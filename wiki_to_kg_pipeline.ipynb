{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "236e29d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# mamba install -c conda-forge langchain langchain-text-splitters langchain-openai langchain-community wikipedia pydantic nbformat nbconvert\n",
    "%pip install -q langchain langchain-text-splitters langchain-openai langchain-community wikipedia pydantic nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "833f695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies loaded (with CID support)\n",
      "Cell timeout: 60s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import hashlib\n",
    "import time\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional\n",
    "from urllib.parse import quote\n",
    "\n",
    "import nbformat\n",
    "from nbformat.v4 import new_notebook, new_markdown_cell, new_code_cell, new_raw_cell\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# === Content ID (CID) Functions ===\n",
    "\n",
    "def compute_cid(content: str) -> str:\n",
    "    \"\"\"Compute SHA256 content ID for a string.\"\"\"\n",
    "    return hashlib.sha256(content.encode('utf-8')).hexdigest()\n",
    "\n",
    "def make_signature(cell_num: int, cell_type: str, cid: str, from_cid: str) -> dict:\n",
    "    \"\"\"Create a signature dict for a generated cell.\"\"\"\n",
    "    return {\n",
    "        \"cell\": cell_num,\n",
    "        \"type\": cell_type,\n",
    "        \"cid\": cid,\n",
    "        \"from_cid\": from_cid,\n",
    "    }\n",
    "\n",
    "def parse_signature(raw_content: str) -> Optional[dict]:\n",
    "    \"\"\"Parse a signature from raw cell content. Returns None if not a valid signature.\"\"\"\n",
    "    try:\n",
    "        data = json.loads(raw_content.strip())\n",
    "        if all(k in data for k in (\"cell\", \"type\", \"cid\", \"from_cid\")):\n",
    "            return data\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def extract_signatures(notebook) -> dict:\n",
    "    \"\"\"Extract all signatures from a notebook, keyed by cell number.\"\"\"\n",
    "    signatures = {}\n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type == 'raw':\n",
    "            sig = parse_signature(cell.source)\n",
    "            if sig:\n",
    "                signatures[sig[\"cell\"]] = sig\n",
    "    return signatures\n",
    "\n",
    "# === Timeout Configuration ===\n",
    "# Note: SIGALRM doesn't work for blocking I/O (HTTP requests)\n",
    "# Instead, we use the timeout parameter on the ChatOpenAI client\n",
    "\n",
    "CELL_TIMEOUT_SECONDS = 60  # 1 minute per cell max\n",
    "\n",
    "def log_progress(msg: str, end=\"\\n\"):\n",
    "    \"\"\"Print with immediate flush for real-time progress.\"\"\"\n",
    "    print(msg, end=end, flush=True)\n",
    "\n",
    "print(\"Dependencies loaded (with CID support)\")\n",
    "print(f\"Cell timeout: {CELL_TIMEOUT_SECONDS}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b252ef95",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f79c403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline configured for: Albert Einstein\n"
     ]
    }
   ],
   "source": [
    "# Pipeline configuration\n",
    "ARTICLE_TITLE = \"Albert Einstein\"\n",
    "OUTPUT_DIR = \"data\"\n",
    "CHUNK_SIZE = 2000\n",
    "CHUNK_OVERLAP = 128\n",
    "\n",
    "# LLM configuration (shared across stages)\n",
    "LLM_CONFIG = {\n",
    "    \"provider\": \"lm_studio\",  # or \"openai\"\n",
    "    \"model\": \"qwen/qwen3-coder-30b\",\n",
    "    \"temperature\": 1,\n",
    "    \"base_url\": os.environ.get(\"LM_STUDIO_BASE_URL\", \"http://host.docker.internal:1234/v1\"),\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Pipeline configured for: {ARTICLE_TITLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df90b5b",
   "metadata": {},
   "source": [
    "## Entity Registry\n",
    "\n",
    "Manages entity identity across chunks with stable URIs derived from source URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a66f9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntityRegistry class defined\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class EntityRegistry:\n",
    "    \"\"\"Tracks entities with stable IDs derived from source URL.\"\"\"\n",
    "    source_url: str\n",
    "    entities: dict = field(default_factory=dict)  # normalized_key -> entity\n",
    "    aliases: dict = field(default_factory=dict)   # alias -> canonical_key\n",
    "    \n",
    "    def normalize_key(self, label: str) -> str:\n",
    "        \"\"\"Create consistent key from entity label.\"\"\"\n",
    "        return re.sub(r'[^a-z0-9]+', '_', label.lower().strip()).strip('_')\n",
    "    \n",
    "    def generate_uri(self, entity_type: str, label: str) -> str:\n",
    "        \"\"\"Generate URI based on source URL with fragment identifier.\"\"\"\n",
    "        key = self.normalize_key(label)\n",
    "        # Use source URL as base, add fragment for entity\n",
    "        return f\"{self.source_url}#{entity_type.lower()}_{key}\"\n",
    "    \n",
    "    def generate_id(self, entity_type: str, label: str) -> str:\n",
    "        \"\"\"Generate local ID for internal reference.\"\"\"\n",
    "        key = self.normalize_key(label)\n",
    "        return f\"{entity_type.lower()}_{key}\"\n",
    "    \n",
    "    def register(self, label: str, entity_type: str, description: str = \"\",\n",
    "                 aliases: list = None, source_chunk: int = None) -> str:\n",
    "        \"\"\"Register or update an entity, return canonical ID.\"\"\"\n",
    "        key = self.normalize_key(label)\n",
    "        entity_id = self.generate_id(entity_type, label)\n",
    "        entity_uri = self.generate_uri(entity_type, label)\n",
    "        \n",
    "        if key not in self.entities:\n",
    "            self.entities[key] = {\n",
    "                \"id\": entity_id,\n",
    "                \"uri\": entity_uri,\n",
    "                \"label\": label,\n",
    "                \"type\": entity_type,\n",
    "                \"descriptions\": [description] if description else [],\n",
    "                \"source_chunks\": [source_chunk] if source_chunk is not None else [],\n",
    "                \"aliases\": list(aliases or []),\n",
    "            }\n",
    "        else:\n",
    "            existing = self.entities[key]\n",
    "            if description and description not in existing[\"descriptions\"]:\n",
    "                existing[\"descriptions\"].append(description)\n",
    "            if source_chunk is not None and source_chunk not in existing[\"source_chunks\"]:\n",
    "                existing[\"source_chunks\"].append(source_chunk)\n",
    "            if aliases:\n",
    "                existing[\"aliases\"] = list(set(existing[\"aliases\"]) | set(aliases))\n",
    "        \n",
    "        # Register aliases\n",
    "        for alias in (aliases or []):\n",
    "            self.aliases[self.normalize_key(alias)] = key\n",
    "        \n",
    "        return entity_id\n",
    "    \n",
    "    def lookup(self, label: str) -> Optional[dict]:\n",
    "        \"\"\"Find entity by label or alias.\"\"\"\n",
    "        key = self.normalize_key(label)\n",
    "        canonical_key = self.aliases.get(key, key)\n",
    "        return self.entities.get(canonical_key)\n",
    "    \n",
    "    def to_json(self) -> str:\n",
    "        \"\"\"Serialize registry to JSON.\"\"\"\n",
    "        return json.dumps({\n",
    "            \"source_url\": self.source_url,\n",
    "            \"entities\": self.entities,\n",
    "            \"aliases\": self.aliases,\n",
    "        }, indent=2)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json(cls, json_str: str) -> 'EntityRegistry':\n",
    "        \"\"\"Deserialize registry from JSON.\"\"\"\n",
    "        data = json.loads(json_str)\n",
    "        registry = cls(source_url=data[\"source_url\"])\n",
    "        registry.entities = data[\"entities\"]\n",
    "        registry.aliases = data[\"aliases\"]\n",
    "        return registry\n",
    "\n",
    "print(\"EntityRegistry class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1094a385",
   "metadata": {},
   "source": [
    "## Section Hierarchy Parser\n",
    "\n",
    "Extracts Wikipedia section structure for breadcrumb context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46fe68df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section hierarchy parser defined\n"
     ]
    }
   ],
   "source": [
    "def extract_section_hierarchy(content: str) -> list[dict]:\n",
    "    \"\"\"Parse Wikipedia == headers == into hierarchical structure with positions.\"\"\"\n",
    "    header_pattern = re.compile(r'^(={2,6})\\s*(.+?)\\s*\\1\\s*$', re.MULTILINE)\n",
    "    \n",
    "    sections = []\n",
    "    current_path = []  # Stack of (level, title)\n",
    "    \n",
    "    for match in header_pattern.finditer(content):\n",
    "        level = len(match.group(1))  # Number of '=' signs\n",
    "        title = match.group(2).strip()\n",
    "        \n",
    "        # Pop stack until we're at parent level\n",
    "        while current_path and current_path[-1][0] >= level:\n",
    "            current_path.pop()\n",
    "        \n",
    "        current_path.append((level, title))\n",
    "        breadcrumb = \" > \".join(t for _, t in current_path)\n",
    "        \n",
    "        sections.append({\n",
    "            \"level\": level,\n",
    "            \"title\": title,\n",
    "            \"breadcrumb\": breadcrumb,\n",
    "            \"start_pos\": match.start(),\n",
    "            \"end_pos\": match.end(),\n",
    "        })\n",
    "    \n",
    "    return sections\n",
    "\n",
    "\n",
    "def get_section_context(position: int, sections: list[dict], article_title: str) -> dict:\n",
    "    \"\"\"Find the section context for a given character position.\"\"\"\n",
    "    active_section = {\n",
    "        \"title\": \"Introduction\",\n",
    "        \"breadcrumb\": \"Introduction\",\n",
    "        \"level\": 1,\n",
    "    }\n",
    "    \n",
    "    for section in sections:\n",
    "        if section[\"start_pos\"] <= position:\n",
    "            active_section = section\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        \"section_title\": active_section[\"title\"],\n",
    "        \"breadcrumb\": f\"{article_title} > {active_section['breadcrumb']}\",\n",
    "    }\n",
    "\n",
    "print(\"Section hierarchy parser defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5360c37f",
   "metadata": {},
   "source": [
    "## Fetch Wikipedia Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91833b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched: Albert Einstein\n",
      "Source URL: https://en.wikipedia.org/wiki/Albert_Einstein\n",
      "Content length: 87959 characters\n",
      "License: CC BY-SA 4.0\n"
     ]
    }
   ],
   "source": [
    "# Fetch Wikipedia article\n",
    "loader = WikipediaLoader(query=ARTICLE_TITLE, load_max_docs=1, doc_content_chars_max=100000)\n",
    "docs = loader.load()\n",
    "\n",
    "if not docs:\n",
    "    raise ValueError(f\"Could not fetch article: {ARTICLE_TITLE}\")\n",
    "\n",
    "raw_content = docs[0].page_content\n",
    "metadata = docs[0].metadata\n",
    "\n",
    "# Construct source URL and provenance\n",
    "source_url = f\"https://en.wikipedia.org/wiki/{quote(ARTICLE_TITLE.replace(' ', '_'))}\"\n",
    "\n",
    "provenance = {\n",
    "    \"source_url\": source_url,\n",
    "    \"article_title\": ARTICLE_TITLE,\n",
    "    \"fetched_at\": datetime.now().isoformat(),\n",
    "    \"content_length\": len(raw_content),\n",
    "    # Wikipedia license - standard for all Wikipedia content\n",
    "    \"license\": \"CC BY-SA 4.0\",\n",
    "    \"license_url\": \"https://creativecommons.org/licenses/by-sa/4.0/\",\n",
    "    \"attribution\": \"Wikipedia contributors\",\n",
    "}\n",
    "\n",
    "print(f\"Fetched: {ARTICLE_TITLE}\")\n",
    "print(f\"Source URL: {source_url}\")\n",
    "print(f\"Content length: {len(raw_content)} characters\")\n",
    "print(f\"License: {provenance['license']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1276b5",
   "metadata": {},
   "source": [
    "## Create Contextual Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3146caad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 71 sections\n",
      "Split into 63 chunks\n",
      "\n",
      "Chunks with context:\n",
      "  Chunk 1: Albert Einstein > Introduction\n",
      "  Chunk 2: Albert Einstein > Introduction\n",
      "  Chunk 3: Albert Einstein > Life and career\n"
     ]
    }
   ],
   "source": [
    "# Parse section hierarchy\n",
    "sections = extract_section_hierarchy(raw_content)\n",
    "print(f\"Found {len(sections)} sections\")\n",
    "\n",
    "# Split into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    ")\n",
    "raw_chunks = splitter.split_text(raw_content)\n",
    "print(f\"Split into {len(raw_chunks)} chunks\")\n",
    "\n",
    "# Add context to each chunk\n",
    "@dataclass\n",
    "class ContextualChunk:\n",
    "    content: str\n",
    "    chunk_index: int\n",
    "    total_chunks: int\n",
    "    breadcrumb: str\n",
    "    section_title: str\n",
    "    char_start: int\n",
    "    char_end: int\n",
    "\n",
    "contextual_chunks = []\n",
    "current_pos = 0\n",
    "\n",
    "for i, chunk_text in enumerate(raw_chunks):\n",
    "    # Find position in original content\n",
    "    chunk_start = raw_content.find(chunk_text, current_pos)\n",
    "    if chunk_start == -1:\n",
    "        chunk_start = current_pos  # Fallback\n",
    "    chunk_end = chunk_start + len(chunk_text)\n",
    "    \n",
    "    # Get section context\n",
    "    context = get_section_context(chunk_start, sections, ARTICLE_TITLE)\n",
    "    \n",
    "    contextual_chunks.append(ContextualChunk(\n",
    "        content=chunk_text,\n",
    "        chunk_index=i,\n",
    "        total_chunks=len(raw_chunks),\n",
    "        breadcrumb=context[\"breadcrumb\"],\n",
    "        section_title=context[\"section_title\"],\n",
    "        char_start=chunk_start,\n",
    "        char_end=chunk_end,\n",
    "    ))\n",
    "    \n",
    "    current_pos = chunk_start + 1\n",
    "\n",
    "print(f\"\\nChunks with context:\")\n",
    "for chunk in contextual_chunks[:3]:\n",
    "    print(f\"  Chunk {chunk.chunk_index + 1}: {chunk.breadcrumb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3af602",
   "metadata": {},
   "source": [
    "## Initialize Entity Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b0e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity registry initialized with subject: Albert Einstein\n",
      "Subject URI: https://en.wikipedia.org/wiki/Albert_Einstein#person_albert_einstein\n"
     ]
    }
   ],
   "source": [
    "# Initialize entity registry with article subject\n",
    "registry = EntityRegistry(source_url=source_url)\n",
    "\n",
    "# Pre-seed with the article subject\n",
    "registry.register(\n",
    "    label=ARTICLE_TITLE,\n",
    "    entity_type=\"Person\",  # Adjust based on article type\n",
    "    description=f\"Subject of Wikipedia article: {ARTICLE_TITLE}\",\n",
    "    aliases=[ARTICLE_TITLE.split()[-1]],  # Last name as alias\n",
    ")\n",
    "\n",
    "print(f\"Entity registry initialized with subject: {ARTICLE_TITLE}\")\n",
    "print(f\"Subject URI: {registry.entities[registry.normalize_key(ARTICLE_TITLE)]['uri']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd3cdd",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "These prompts are embedded in the generated notebooks for transparency and adjustability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3089027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt templates defined\n"
     ]
    }
   ],
   "source": [
    "FACTS_EXTRACTION_PROMPT = \"\"\"You are an expert at extracting factual information from text.\n",
    "\n",
    "Given text from a Wikipedia article, extract simple English statements that capture the consensus factual information. Each statement should:\n",
    "- Be a single, clear sentence\n",
    "- Contain one main fact or relationship\n",
    "- Use the full name of entities on first mention\n",
    "- Be verifiable from the source text\n",
    "- Avoid opinions, interpretations, or hedged language\n",
    "\n",
    "The text comes from: {source_url}\n",
    "Section context: {breadcrumb}\n",
    "\n",
    "Known entities (use consistent names):\n",
    "{known_entities}\n",
    "\n",
    "---\n",
    "{chunk_text}\n",
    "---\n",
    "\n",
    "Extract factual statements as a bulleted list. Also identify any new entities (people, places, organizations, concepts, events, works) that should be added to the registry.\n",
    "\"\"\"\n",
    "\n",
    "RDF_GENERATION_PROMPT = \"\"\"You are an expert at converting factual statements to RDF triples in Turtle format.\n",
    "\n",
    "Convert the following factual statements to RDF using schema.org vocabulary where possible.\n",
    "\n",
    "Source: {source_url}\n",
    "Section: {breadcrumb}\n",
    "\n",
    "Use these prefixes:\n",
    "{prefixes}\n",
    "\n",
    "Entity registry (use these URIs):\n",
    "{entity_registry}\n",
    "\n",
    "Guidelines:\n",
    "- Use schema.org properties (schema:birthDate, schema:birthPlace, schema:worksFor, etc.)\n",
    "- For relationships not in schema.org, use wiki3: prefix\n",
    "- Include rdfs:label for entities\n",
    "- Use xsd datatypes for dates and numbers\n",
    "- Entity URIs should use the source URL as base with fragment identifiers\n",
    "\n",
    "---\n",
    "{facts}\n",
    "---\n",
    "\n",
    "Generate Turtle RDF:\n",
    "\"\"\"\n",
    "\n",
    "RDF_PREFIXES = \"\"\"@prefix schema: <https://schema.org/> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "@prefix wiki3: <https://wiki3.ai/vocab/> .\n",
    "@base <{source_url}> .\n",
    "\"\"\"\n",
    "\n",
    "print(\"Prompt templates defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa35e61",
   "metadata": {},
   "source": [
    "## Generate Chunks Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d121080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: data/albert_einstein_chunks.ipynb\n"
     ]
    }
   ],
   "source": [
    "def generate_chunks_notebook(chunks: list, provenance: dict, registry: EntityRegistry, \n",
    "                             llm_config: dict, output_path: str):\n",
    "    \"\"\"Generate a notebook with chunked source text and context metadata.\n",
    "    \n",
    "    Each chunk cell is followed by a signature raw cell with its CID.\n",
    "    \"\"\"\n",
    "    nb = new_notebook()\n",
    "    \n",
    "    # Cell 0: Provenance markdown\n",
    "    provenance_yaml = f\"\"\"# Chunked Text: {provenance['article_title']}\n",
    "\n",
    "## Provenance\n",
    "\n",
    "```yaml\n",
    "source_url: {provenance['source_url']}\n",
    "article_title: {provenance['article_title']}\n",
    "fetched_at: {provenance['fetched_at']}\n",
    "content_length: {provenance['content_length']}\n",
    "license: {provenance['license']}\n",
    "license_url: {provenance['license_url']}\n",
    "attribution: {provenance['attribution']}\n",
    "chunk_size: {CHUNK_SIZE}\n",
    "chunk_overlap: {CHUNK_OVERLAP}\n",
    "total_chunks: {len(chunks)}\n",
    "generated_by: wiki_to_kg_pipeline.ipynb\n",
    "generated_at: {datetime.now().isoformat()}\n",
    "```\n",
    "\n",
    "## Processing Instructions\n",
    "\n",
    "Each chunk below contains source text with contextual metadata. The context line (before the separator) provides:\n",
    "- **Context**: Hierarchical breadcrumb showing article > section path\n",
    "- **Chunk**: Position in sequence\n",
    "\n",
    "The text below the `---` separator is the unchanged source content.\n",
    "Each chunk is followed by a signature cell containing its Content ID (CID).\n",
    "\"\"\"\n",
    "    nb.cells.append(new_markdown_cell(provenance_yaml))\n",
    "    \n",
    "    # Cell 1: Entity registry (raw cell)\n",
    "    nb.cells.append(new_raw_cell(registry.to_json()))\n",
    "    \n",
    "    # Chunk cells with signatures\n",
    "    # Compute CID of raw source for provenance\n",
    "    source_cid = compute_cid(provenance['source_url'] + str(provenance['content_length']))\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # Content cell\n",
    "        chunk_content = f\"\"\"**Context:** {chunk.breadcrumb}\n",
    "**Chunk:** {chunk.chunk_index + 1} of {chunk.total_chunks}\n",
    "\n",
    "---\n",
    "\n",
    "{chunk.content}\n",
    "\"\"\"\n",
    "        nb.cells.append(new_markdown_cell(chunk_content))\n",
    "        \n",
    "        # Signature cell\n",
    "        chunk_cid = compute_cid(chunk_content)\n",
    "        signature = make_signature(\n",
    "            cell_num=chunk.chunk_index + 1,\n",
    "            cell_type=\"chunk\",\n",
    "            cid=chunk_cid,\n",
    "            from_cid=source_cid\n",
    "        )\n",
    "        nb.cells.append(new_raw_cell(json.dumps(signature)))\n",
    "    \n",
    "    # Write notebook\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(nb, f)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Generate chunks notebook\n",
    "article_slug = ARTICLE_TITLE.lower().replace(' ', '_')\n",
    "chunks_path = os.path.join(OUTPUT_DIR, f\"{article_slug}_chunks.ipynb\")\n",
    "generate_chunks_notebook(contextual_chunks, provenance, registry, LLM_CONFIG, chunks_path)\n",
    "print(f\"Generated: {chunks_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c23dc4",
   "metadata": {},
   "source": [
    "## Generate Facts Notebook (Structure Only)\n",
    "\n",
    "Creates the facts notebook with placeholders. Actual content is generated in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cd4acab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created facts notebook: data/albert_einstein_facts.ipynb\n"
     ]
    }
   ],
   "source": [
    "def generate_facts_notebook_header(provenance: dict, registry: EntityRegistry,\n",
    "                                    llm_config: dict, prompt_template: str) -> nbformat.NotebookNode:\n",
    "    \"\"\"Generate just the header cells for facts notebook.\"\"\"\n",
    "    nb = new_notebook()\n",
    "    \n",
    "    provenance_md = f\"\"\"# Factual Statements: {provenance['article_title']}\n",
    "\n",
    "## Provenance\n",
    "\n",
    "```yaml\n",
    "source_url: {provenance['source_url']}\n",
    "article_title: {provenance['article_title']}\n",
    "license: {provenance['license']}\n",
    "license_url: {provenance['license_url']}\n",
    "source_notebook: {article_slug}_chunks.ipynb\n",
    "generated_by: wiki_to_kg_pipeline.ipynb\n",
    "generated_at: {datetime.now().isoformat()}\n",
    "llm_provider: {llm_config['provider']}\n",
    "llm_model: {llm_config['model']}\n",
    "llm_temperature: {llm_config['temperature']}\n",
    "```\n",
    "\n",
    "## Processing Instructions\n",
    "\n",
    "This notebook contains simple English factual statements extracted from source text chunks.\n",
    "Each content cell corresponds to one chunk from the source notebook.\n",
    "Each content cell is followed by a signature cell with CID provenance.\n",
    "\n",
    "To regenerate a specific cell: delete both the content cell and its signature, then re-run the pipeline.\n",
    "\n",
    "## Prompt Template\n",
    "\n",
    "```\n",
    "{prompt_template}\n",
    "```\n",
    "\"\"\"\n",
    "    nb.cells.append(new_markdown_cell(provenance_md))\n",
    "    nb.cells.append(new_raw_cell(registry.to_json()))\n",
    "    \n",
    "    return nb\n",
    "\n",
    "# Create initial facts notebook with just header (no placeholders)\n",
    "facts_path = os.path.join(OUTPUT_DIR, f\"{article_slug}_facts.ipynb\")\n",
    "\n",
    "# Only create if doesn't exist\n",
    "if not os.path.exists(facts_path):\n",
    "    facts_nb = generate_facts_notebook_header(provenance, registry, LLM_CONFIG, FACTS_EXTRACTION_PROMPT)\n",
    "    with open(facts_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(facts_nb, f)\n",
    "    print(f\"Created facts notebook: {facts_path}\")\n",
    "else:\n",
    "    print(f\"Facts notebook exists: {facts_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256713fd",
   "metadata": {},
   "source": [
    "## Generate RDF Notebook (Structure Only)\n",
    "\n",
    "Creates the RDF notebook with placeholders. Actual content is generated after facts extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a7ae750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created RDF notebook: data/albert_einstein_rdf.ipynb\n"
     ]
    }
   ],
   "source": [
    "def generate_rdf_notebook_header(provenance: dict, registry: EntityRegistry,\n",
    "                                  llm_config: dict, prompt_template: str, prefixes: str) -> nbformat.NotebookNode:\n",
    "    \"\"\"Generate just the header cells for RDF notebook.\"\"\"\n",
    "    nb = new_notebook()\n",
    "    \n",
    "    formatted_prefixes = prefixes.format(source_url=provenance['source_url'])\n",
    "    provenance_md = f\"\"\"# RDF Triples: {provenance['article_title']}\n",
    "\n",
    "## Provenance\n",
    "\n",
    "```yaml\n",
    "source_url: {provenance['source_url']}\n",
    "article_title: {provenance['article_title']}\n",
    "license: {provenance['license']}\n",
    "license_url: {provenance['license_url']}\n",
    "source_notebook: {article_slug}_facts.ipynb\n",
    "generated_by: wiki_to_kg_pipeline.ipynb\n",
    "generated_at: {datetime.now().isoformat()}\n",
    "llm_provider: {llm_config['provider']}\n",
    "llm_model: {llm_config['model']}\n",
    "llm_temperature: {llm_config['temperature']}\n",
    "rdf_format: Turtle\n",
    "```\n",
    "\n",
    "## RDF Prefixes\n",
    "\n",
    "```turtle\n",
    "{formatted_prefixes}\n",
    "```\n",
    "\n",
    "## Processing Instructions\n",
    "\n",
    "This notebook contains RDF triples in Turtle format, one cell per source facts cell.\n",
    "Each content cell is followed by a signature cell with CID provenance.\n",
    "\n",
    "To regenerate a specific cell: delete both the content cell and its signature, then re-run the pipeline.\n",
    "\n",
    "## Prompt Template\n",
    "\n",
    "```\n",
    "{prompt_template}\n",
    "```\n",
    "\"\"\"\n",
    "    nb.cells.append(new_markdown_cell(provenance_md))\n",
    "    nb.cells.append(new_raw_cell(registry.to_json()))\n",
    "    \n",
    "    return nb\n",
    "\n",
    "# Create initial RDF notebook with just header (no placeholders)\n",
    "rdf_path = os.path.join(OUTPUT_DIR, f\"{article_slug}_rdf.ipynb\")\n",
    "\n",
    "# Only create if doesn't exist\n",
    "if not os.path.exists(rdf_path):\n",
    "    rdf_nb = generate_rdf_notebook_header(provenance, registry, LLM_CONFIG, RDF_GENERATION_PROMPT, RDF_PREFIXES)\n",
    "    with open(rdf_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(rdf_nb, f)\n",
    "    print(f\"Created RDF notebook: {rdf_path}\")\n",
    "else:\n",
    "    print(f\"RDF notebook exists: {rdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696afdf",
   "metadata": {},
   "source": [
    "## Process Chunks → Extract Facts\n",
    "\n",
    "Run the LLM on each chunk to extract factual statements and update the facts notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc2350ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks notebook...\n",
      "Found 63 chunks with CIDs\n",
      "Found 0 existing fact signatures\n",
      "HTTP timeout: 60s per request\n",
      "--------------------------------------------------\n",
      "  Chunk 1: + Generating\n",
      "    Context: Albert Einstein > Introduction\n",
      "    Input: Albert Einstein (14 March 1879 – 18 April 1955) was a German-born theoretical ph...\n",
      "    [Calling LLM...] ✓ (2206 chars, 6.6s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 2: + Generating\n",
      "    Context: Albert Einstein > Introduction\n",
      "    Input: In 1905, sometimes described as his annus mirabilis (miracle year), he published...\n",
      "    [Calling LLM...] ✓ (1732 chars, 4.6s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 3: + Generating\n",
      "    Context: Albert Einstein > Life and career\n",
      "    Input: == Life and career ==   === Childhood, youth and education ===  Albert Einstein ...\n",
      "    [Calling LLM...] ✓ (1146 chars, 3.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 4: + Generating\n",
      "    Context: Albert Einstein > Life and career > Childhood, youth and education\n",
      "    Input: In 1894, Hermann and Jakob's company tendered for a contract to install electric...\n",
      "    [Calling LLM...] ✓ (1073 chars, 3.2s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 5: + Generating\n",
      "    Context: Albert Einstein > Life and career > Childhood, youth and education\n",
      "    Input: Einstein excelled at physics and mathematics from an early age, and soon acquire...\n",
      "    [Calling LLM...] ✓ (1076 chars, 2.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 6: + Generating\n",
      "    Context: Albert Einstein > Life and career > Childhood, youth and education\n",
      "    Input: At thirteen, when his range of enthusiasms had broadened to include music and ph...\n",
      "    [Calling LLM...] ✓ (910 chars, 2.6s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 7: + Generating\n",
      "    Context: Albert Einstein > Life and career > Childhood, youth and education\n",
      "    Input: In January 1896, with his father's approval, Einstein renounced his citizenship ...\n",
      "    [Calling LLM...] ✓ (1518 chars, 4.2s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 8: + Generating\n",
      "    Context: Albert Einstein > Life and career > Marriages, relationships and children\n",
      "    Input: === Marriages, relationships and children ===  Correspondence between Einstein a...\n",
      "    [Calling LLM...] ✓ (1668 chars, 5.8s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 9: + Generating\n",
      "    Context: Albert Einstein > Life and career > Marriages, relationships and children\n",
      "    Input: A volume of Einstein's letters released by Hebrew University of Jerusalem in 200...\n",
      "    [Calling LLM...] ✓ (1661 chars, 5.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 10: + Generating\n",
      "    Context: Albert Einstein > Life and career > Assistant at the Swiss Patent Office (1902–1909)\n",
      "    Input: === Assistant at the Swiss Patent Office (1902–1909) ===  Einstein graduated fro...\n",
      "    [Calling LLM...] ✓ (1647 chars, 4.2s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 11: + Generating\n",
      "    Context: Albert Einstein > Life and career > First scientific papers (1900–1905)\n",
      "    Input: === First scientific papers (1900–1905) ===  Einstein's first paper, \"Folgerunge...\n",
      "    [Calling LLM...] ✓ (1630 chars, 5.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 12: + Generating\n",
      "    Context: Albert Einstein > Life and career > Academic career in Europe (1908–1933)\n",
      "    Input: From 30 October to 3 November 1911, Einstein attended the first Solvay Conferenc...\n",
      "    [Calling LLM...] ✓ (1533 chars, 4.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 13: + Generating\n",
      "    Context: Albert Einstein > Life and career > Academic career in Europe (1908–1933)\n",
      "    Input: The outbreak of the First World War in July 1914 marked the beginning of Einstei...\n",
      "    [Calling LLM...] ✓ (1419 chars, 4.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 14: + Generating\n",
      "    Context: Albert Einstein > Life and career > Academic career in Europe (1908–1933)\n",
      "    Input: Einstein resigned from the Prussian Academy in March 1933. His accomplishments i...\n",
      "    [Calling LLM...] ✓ (399 chars, 1.1s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 15: + Generating\n",
      "    Context: Albert Einstein > Life and career > Putting general relativity to the test (1919)\n",
      "    Input: === Putting general relativity to the test (1919) ===  In 1907, Einstein reached...\n",
      "    [Calling LLM...] ✓ (1270 chars, 3.9s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 16: + Generating\n",
      "    Context: Albert Einstein > Life and career > Coming to terms with fame (1921–1923)\n",
      "    Input: With Eddington's eclipse observations widely reported not just in academic journ...\n",
      "    [Calling LLM...] ✓ (1146 chars, 3.2s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 17: + Generating\n",
      "    Context: Albert Einstein > Life and career > Coming to terms with fame (1921–1923)\n",
      "    Input: In 1922, Einstein's travels were to the old world rather than the new. He devote...\n",
      "    [Calling LLM...] ✓ (1156 chars, 3.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 18: + Generating\n",
      "    Context: Albert Einstein > Life and career > Coming to terms with fame (1921–1923)\n",
      "    Input: Einstein's decision to tour the eastern hemisphere in 1922 meant that he was una...\n",
      "    [Calling LLM...] ✓ (768 chars, 2.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 19: + Generating\n",
      "    Context: Albert Einstein > Life and career > Serving the League of Nations (1922–1932)\n",
      "    Input: === Serving the League of Nations (1922–1932) ===  From 1922 until 1932, with th...\n",
      "    [Calling LLM...] ✓ (1146 chars, 3.2s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 20: + Generating\n",
      "    Context: Albert Einstein > Life and career > Touring the US (1930–1931)\n",
      "    Input: === Touring the US (1930–1931) ===  In December 1930, Einstein began another sig...\n",
      "    [Calling LLM...] ✓ (1223 chars, 3.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 21: + Generating\n",
      "    Context: Albert Einstein > Life and career > Touring the US (1930–1931)\n",
      "    Input: Einstein next traveled to California, where he met Caltech president and Nobel l...\n",
      "    [Calling LLM...] ✓ (1868 chars, 5.2s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 22: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933)\n",
      "    Input: === Emigration to the US (1933) ===  In February 1933, while on a visit to the U...\n",
      "    [Calling LLM...] ✓ (1242 chars, 4.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 23: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > Refugee status\n",
      "    Input: In April 1933, Einstein discovered that the new German government had passed law...\n",
      "    [Calling LLM...] ✓ (1209 chars, 3.6s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 24: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > Refugee status\n",
      "    Input: Einstein was now without a permanent home, unsure where he would live and work, ...\n",
      "    [Calling LLM...] ✓ (1136 chars, 3.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 25: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > Refugee status\n",
      "    Input: Locker-Lampson took Einstein to meet Winston Churchill at his home, and later, A...\n",
      "    [Calling LLM...] ✓ (1315 chars, 3.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 26: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > Resident scholar at the Institute for Advanced Study\n",
      "    Input: ==== Resident scholar at the Institute for Advanced Study ====  On 3 October 193...\n",
      "    [Calling LLM...] ✓ (1070 chars, 3.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 27: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > World War II and the Manhattan Project\n",
      "    Input: In 1939, a group of Hungarian scientists that included émigré physicist Leó Szil...\n",
      "    [Calling LLM...] ✓ (1571 chars, 4.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 28: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > World War II and the Manhattan Project\n",
      "    Input: For Einstein, \"war was a disease ... [and] he called for resistance to war.\" By ...\n",
      "    [Calling LLM...] ✓ (877 chars, 2.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 29: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > US citizenship\n",
      "    Input: ==== US citizenship ====...\n",
      "    [Calling LLM...] ✓ (860 chars, 2.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 30: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > US citizenship\n",
      "    Input: Einstein became an American citizen in 1940. Not long after settling into his ca...\n",
      "    [Calling LLM...] ✓ (651 chars, 2.1s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 31: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > US citizenship\n",
      "    Input: In 1946, Einstein visited Lincoln University in Pennsylvania, a historically bla...\n",
      "    [Calling LLM...] ✓ (1254 chars, 3.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 32: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views\n",
      "    Input: === Personal views ===   ==== Political views ====  In 1918, Einstein was one of...\n",
      "    [Calling LLM...] ✓ (599 chars, 1.9s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 33: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views > Political views\n",
      "    Input: In Lenin I honor a man, who in total sacrifice of his own person has committed h...\n",
      "    [Calling LLM...] ✓ (1058 chars, 3.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 34: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views > Relationship with Zionism\n",
      "    Input: ==== Relationship with Zionism ====  Einstein was a figurehead leader in the est...\n",
      "    [Calling LLM...] ✓ (1222 chars, 3.6s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 35: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views > Religious and philosophical views\n",
      "    Input: ==== Religious and philosophical views ====  Per Lee Smolin, \"I believe what all...\n",
      "    [Calling LLM...] ✓ (989 chars, 2.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 36: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views > Religious and philosophical views\n",
      "    Input: The word God is for me nothing more than the expression and product of human wea...\n",
      "    [Calling LLM...] ✓ (689 chars, 1.8s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 37: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views > Love of music\n",
      "    Input: If I were not a physicist, I would probably be a musician. I often think in musi...\n",
      "    [Calling LLM...] ✓ (1350 chars, 3.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 38: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views > Love of music\n",
      "    Input: Music took on a pivotal and permanent role in Einstein's life from that period o...\n",
      "    [Calling LLM...] ✓ (1207 chars, 3.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 39: + Generating\n",
      "    Context: Albert Einstein > Life and career > Death\n",
      "    Input: === Death === On 17 April 1955, Einstein experienced internal bleeding caused by...\n",
      "    [Calling LLM...] ✓ (1194 chars, 3.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 40: + Generating\n",
      "    Context: Albert Einstein > Scientific career\n",
      "    Input: == Scientific career == Throughout his life, Einstein published hundreds of book...\n",
      "    [Calling LLM...] ✓ (968 chars, 3.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 41: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Statistical mechanics > Theory of critical opalescence\n",
      "    Input: ==== Theory of critical opalescence ====  Einstein returned to the problem of th...\n",
      "    [Calling LLM...] ✓ (1548 chars, 4.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 42: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Special relativity\n",
      "    Input: === Special relativity ===  Einstein's \"Zur Elektrodynamik bewegter Körper\" (\"On...\n",
      "    [Calling LLM...] ✓ (1331 chars, 4.1s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 43: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity\n",
      "    Input: === General relativity ===   ==== General relativity and the equivalence princip...\n",
      "    [Calling LLM...] ✓ (1440 chars, 4.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 44: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity > Gravitational waves\n",
      "    Input: ==== Gravitational waves ==== In 1916, Einstein predicted gravitational waves, r...\n",
      "    [Calling LLM...] ✓ (1544 chars, 4.1s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 45: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity > Physical cosmology\n",
      "    Input: In 1917, Einstein applied the general theory of relativity to the structure of t...\n",
      "    [Calling LLM...] ✓ (1511 chars, 4.1s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 46: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity > Physical cosmology\n",
      "    Input: In late 2013, a team led by the Irish physicist Cormac O'Raifeartaigh discovered...\n",
      "    [Calling LLM...] ✓ (1150 chars, 3.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 47: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity > Energy momentum pseudotensor\n",
      "    Input: ==== Energy momentum pseudotensor ====  General relativity includes a dynamical ...\n",
      "    [Calling LLM...] ✓ (778 chars, 2.2s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 48: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity > Einstein–Cartan theory\n",
      "    Input: ==== Einstein–Cartan theory ====  In order to incorporate spinning point particl...\n",
      "    [Calling LLM...] ✓ (339 chars, 1.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 49: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity > Equations of motion\n",
      "    Input: ==== Equations of motion ====  In general relativity, gravitational force is rei...\n",
      "    [Calling LLM...] ✓ (1302 chars, 3.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 50: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Old quantum theory\n",
      "    Input: === Old quantum theory ===   ==== Photons and energy quanta ====  In a 1905 pape...\n",
      "    [Calling LLM...] ✓ (1247 chars, 3.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 51: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Old quantum theory > Bose–Einstein statistics\n",
      "    Input: ==== Bose–Einstein statistics ====  In 1924, Einstein received a description of ...\n",
      "    [Calling LLM...] ✓ (1670 chars, 4.8s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 52: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Old quantum theory > Zero-point energy\n",
      "    Input: ==== Zero-point energy ==== In a series of works completed from 1911 to 1913, Pl...\n",
      "    [Calling LLM...] ✓ (1484 chars, 4.1s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 53: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Quantum mechanics\n",
      "    Input: === Quantum mechanics ===   ==== Einstein's objections to quantum mechanics ====...\n",
      "    [Calling LLM...] ✓ (1020 chars, 2.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 54: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Quantum mechanics > Einstein–Podolsky–Rosen paradox\n",
      "    Input: Einstein never fully accepted quantum mechanics. While he recognized that it mad...\n",
      "    [Calling LLM...] ✓ (1391 chars, 3.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 55: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Quantum mechanics > Einstein–Podolsky–Rosen paradox\n",
      "    Input: A more famous version of this argument came in 1935, when Einstein published a p...\n",
      "    [Calling LLM...] ✓ (1695 chars, 4.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 56: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Quantum mechanics > Einstein–Podolsky–Rosen paradox\n",
      "    Input: In 1964, John Stewart Bell carried the analysis of quantum entanglement much fur...\n",
      "    [Calling LLM...] ✓ (734 chars, 1.9s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 57: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Unified field theory\n",
      "    Input: === Unified field theory ===  Encouraged by his success with general relativity,...\n",
      "    [Calling LLM...] ✓ (1135 chars, 2.8s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 58: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Collaboration with other scientists > Einstein–de Haas experiment\n",
      "    Input: ==== Einstein–de Haas experiment ====  In 1908, Owen Willans Richardson predicte...\n",
      "    [Calling LLM...] ✓ (1586 chars, 4.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 59: + Generating\n",
      "    Context: Albert Einstein > Legacy\n",
      "    Input: == Legacy ==   === Non-scientific ===  While traveling, Einstein wrote daily to ...\n",
      "    [Calling LLM...] ✓ (1893 chars, 5.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 60: + Generating\n",
      "    Context: Albert Einstein > Legacy > Scientific\n",
      "    Input: === Scientific === In 1999, a survey of the top 100 physicists voted for Einstei...\n",
      "    [Calling LLM...] ✓ (977 chars, 3.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 61: + Generating\n",
      "    Context: Albert Einstein > In popular culture\n",
      "    Input: == In popular culture ==  Einstein became one of the most famous scientific cele...\n",
      "    [Calling LLM...] ✓ (1324 chars, 3.6s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 62: + Generating\n",
      "    Context: Albert Einstein > Publications\n",
      "    Input: == Publications ==   === Scientific ===   === Popular ===   === Political === Ei...\n",
      "    [Calling LLM...] ✓ (1162 chars, 3.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Chunk 63: + Generating\n",
      "    Context: Albert Einstein > External links > Archival materials collections\n",
      "    Input: === Archival materials collections === Albert Einstein Historical Letters, Docum...\n",
      "    [Calling LLM...] ✓ (1217 chars, 3.2s)\n",
      "    [Saving notebook...] saved\n",
      "--------------------------------------------------\n",
      "Facts extraction complete:\n",
      "  - 63 generated\n",
      "  - 0 skipped (up-to-date)\n",
      "  - 0 errors/timeouts\n"
     ]
    }
   ],
   "source": [
    "# Create LLM client with timeout for facts extraction\n",
    "facts_llm = ChatOpenAI(\n",
    "    model=LLM_CONFIG[\"model\"],\n",
    "    temperature=LLM_CONFIG[\"temperature\"],\n",
    "    base_url=LLM_CONFIG[\"base_url\"],\n",
    "    api_key=\"lm-studio\",\n",
    "    timeout=CELL_TIMEOUT_SECONDS,  # HTTP timeout in seconds\n",
    "    max_retries=0,  # Don't retry on timeout\n",
    ")\n",
    "\n",
    "# Create facts extraction prompt\n",
    "facts_prompt = ChatPromptTemplate.from_template(\"\"\"You are an expert at extracting factual information from text.\n",
    "\n",
    "Given text from a Wikipedia article, extract simple English statements that capture the consensus factual information. Each statement should:\n",
    "- Be a single, clear sentence\n",
    "- Contain one main fact or relationship\n",
    "- Use the full name of entities on first mention\n",
    "- Be verifiable from the source text\n",
    "- Avoid opinions, interpretations, or hedged language\n",
    "\n",
    "Source: {source_url}\n",
    "Section context: {breadcrumb}\n",
    "\n",
    "Known entities (use consistent names):\n",
    "{known_entities}\n",
    "\n",
    "---\n",
    "{chunk_text}\n",
    "---\n",
    "\n",
    "Extract factual statements as a bulleted list:\"\"\")\n",
    "\n",
    "facts_chain = facts_prompt | facts_llm\n",
    "\n",
    "def get_known_entities_text(registry: EntityRegistry) -> str:\n",
    "    \"\"\"Format known entities for prompt context.\"\"\"\n",
    "    lines = []\n",
    "    for entity in registry.entities.values():\n",
    "        lines.append(f\"- {entity['label']} ({entity['type']})\")\n",
    "    return \"\\n\".join(lines) if lines else \"None yet\"\n",
    "\n",
    "# Read chunks notebook to get source content and CIDs\n",
    "log_progress(\"Reading chunks notebook...\")\n",
    "chunks_nb = nbformat.read(chunks_path, as_version=4)\n",
    "chunk_signatures = extract_signatures(chunks_nb)\n",
    "\n",
    "# Build list of chunk content with CIDs\n",
    "# Chunks notebook structure: [provenance, registry, chunk1, sig1, chunk2, sig2, ...]\n",
    "chunk_data = []\n",
    "cell_idx = 2  # Skip provenance and registry\n",
    "while cell_idx < len(chunks_nb.cells):\n",
    "    cell = chunks_nb.cells[cell_idx]\n",
    "    if cell.cell_type == 'markdown':\n",
    "        content = cell.source\n",
    "        # Get corresponding signature (next cell)\n",
    "        sig = None\n",
    "        if cell_idx + 1 < len(chunks_nb.cells):\n",
    "            sig = parse_signature(chunks_nb.cells[cell_idx + 1].source)\n",
    "        \n",
    "        # Extract breadcrumb\n",
    "        context_match = re.search(r'\\*\\*Context:\\*\\*\\s*(.+)', content)\n",
    "        breadcrumb = context_match.group(1) if context_match else \"Unknown\"\n",
    "        \n",
    "        # Extract chunk text (after ---)\n",
    "        parts = content.split(\"---\\n\", 1)\n",
    "        chunk_text = parts[1].strip() if len(parts) > 1 else content\n",
    "        \n",
    "        chunk_data.append({\n",
    "            \"cell_num\": sig[\"cell\"] if sig else len(chunk_data) + 1,\n",
    "            \"content\": content,\n",
    "            \"chunk_text\": chunk_text,\n",
    "            \"breadcrumb\": breadcrumb,\n",
    "            \"cid\": sig[\"cid\"] if sig else compute_cid(content),\n",
    "        })\n",
    "        cell_idx += 2  # Skip content and signature\n",
    "    else:\n",
    "        cell_idx += 1\n",
    "\n",
    "log_progress(f\"Found {len(chunk_data)} chunks with CIDs\")\n",
    "\n",
    "# Read existing facts notebook and extract signatures\n",
    "facts_nb = nbformat.read(facts_path, as_version=4)\n",
    "facts_signatures = extract_signatures(facts_nb)\n",
    "\n",
    "log_progress(f\"Found {len(facts_signatures)} existing fact signatures\")\n",
    "log_progress(f\"HTTP timeout: {CELL_TIMEOUT_SECONDS}s per request\")\n",
    "log_progress(\"-\" * 50)\n",
    "\n",
    "# Process each chunk\n",
    "processed_count = 0\n",
    "skipped_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for chunk in chunk_data:\n",
    "    cell_num = chunk[\"cell_num\"]\n",
    "    source_cid = chunk[\"cid\"]\n",
    "    \n",
    "    # Check if we already have up-to-date facts for this chunk\n",
    "    existing_sig = facts_signatures.get(cell_num)\n",
    "    if existing_sig and existing_sig[\"from_cid\"] == source_cid:\n",
    "        log_progress(f\"  Chunk {cell_num}: ⊘ Up-to-date (CID match), skipping\")\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Need to generate (or regenerate) this cell\n",
    "    status = \"↻ Regenerating\" if existing_sig else \"+ Generating\"\n",
    "    chunk_preview = chunk[\"chunk_text\"][:80].replace('\\n', ' ')\n",
    "    log_progress(f\"  Chunk {cell_num}: {status}\")\n",
    "    log_progress(f\"    Context: {chunk['breadcrumb']}\")\n",
    "    log_progress(f\"    Input: {chunk_preview}...\")\n",
    "    log_progress(f\"    [Calling LLM...]\", end=\" \")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Call LLM to extract facts\n",
    "    try:\n",
    "        result = facts_chain.invoke({\n",
    "            \"source_url\": provenance[\"source_url\"],\n",
    "            \"breadcrumb\": chunk[\"breadcrumb\"],\n",
    "            \"known_entities\": get_known_entities_text(registry),\n",
    "            \"chunk_text\": chunk[\"chunk_text\"],\n",
    "        })\n",
    "        facts_content = result.content\n",
    "        elapsed = time.time() - start_time\n",
    "        log_progress(f\"✓ ({len(facts_content)} chars, {elapsed:.1f}s)\")\n",
    "        processed_count += 1\n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - start_time\n",
    "        error_type = type(e).__name__\n",
    "        error_msg = str(e)[:100]\n",
    "        facts_content = f\"# Error: {error_type}: {e}\"\n",
    "        log_progress(f\"✗ {error_type} after {elapsed:.1f}s\")\n",
    "        log_progress(f\"    Error: {error_msg}\")\n",
    "        error_count += 1\n",
    "    \n",
    "    # Build the facts cell content\n",
    "    facts_cell_content = f\"\"\"**Context:** {chunk['breadcrumb']}\n",
    "**Chunk:** {cell_num} of {len(chunk_data)}\n",
    "\n",
    "---\n",
    "\n",
    "{facts_content}\n",
    "\"\"\"\n",
    "    facts_cid = compute_cid(facts_cell_content)\n",
    "    signature = make_signature(cell_num, \"facts\", facts_cid, source_cid)\n",
    "    \n",
    "    # Find where to insert/update in the notebook\n",
    "    # If there's an existing signature for this cell, find and remove old content+sig\n",
    "    if existing_sig:\n",
    "        # Find and remove the old cells\n",
    "        new_cells = [facts_nb.cells[0], facts_nb.cells[1]]  # Keep header\n",
    "        i = 2\n",
    "        while i < len(facts_nb.cells):\n",
    "            cell = facts_nb.cells[i]\n",
    "            if cell.cell_type == 'raw':\n",
    "                sig = parse_signature(cell.source)\n",
    "                if sig and sig[\"cell\"] == cell_num:\n",
    "                    # Skip this signature and its preceding content cell\n",
    "                    i += 1\n",
    "                    continue\n",
    "            # Check if this is content for the cell we're replacing\n",
    "            if i > 0 and i + 1 < len(facts_nb.cells):\n",
    "                next_sig = parse_signature(facts_nb.cells[i + 1].source) if facts_nb.cells[i + 1].cell_type == 'raw' else None\n",
    "                if next_sig and next_sig[\"cell\"] == cell_num:\n",
    "                    i += 2  # Skip content and signature\n",
    "                    continue\n",
    "            new_cells.append(cell)\n",
    "            i += 1\n",
    "        facts_nb.cells = new_cells\n",
    "    \n",
    "    # Append new content and signature\n",
    "    facts_nb.cells.append(new_markdown_cell(facts_cell_content))\n",
    "    facts_nb.cells.append(new_raw_cell(json.dumps(signature)))\n",
    "    \n",
    "    # Update signatures dict\n",
    "    facts_signatures[cell_num] = signature\n",
    "    \n",
    "    # Save notebook after each cell\n",
    "    log_progress(f\"    [Saving notebook...]\", end=\" \")\n",
    "    with open(facts_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(facts_nb, f)\n",
    "    log_progress(\"saved\")\n",
    "\n",
    "log_progress(\"-\" * 50)\n",
    "log_progress(f\"Facts extraction complete:\")\n",
    "log_progress(f\"  - {processed_count} generated\")\n",
    "log_progress(f\"  - {skipped_count} skipped (up-to-date)\")\n",
    "log_progress(f\"  - {error_count} errors/timeouts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60d29b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facts notebook: data/albert_einstein_facts.ipynb\n",
      "  - Updated incrementally during processing\n",
      "  - Ready for review/editing before RDF generation\n"
     ]
    }
   ],
   "source": [
    "# Summary of facts extraction (notebook already updated incrementally)\n",
    "print(f\"Facts notebook: {facts_path}\")\n",
    "print(f\"  - Updated incrementally during processing\")\n",
    "print(f\"  - Ready for review/editing before RDF generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de7f1f",
   "metadata": {},
   "source": [
    "## Process Facts → Generate RDF\n",
    "\n",
    "Run the LLM on each facts cell to generate RDF triples and update the RDF notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afd0797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded schema matcher with 1 vocabularies\n",
      "Reading facts notebook...\n",
      "Found 63 facts cells with CIDs\n",
      "Found 0 existing RDF signatures\n",
      "HTTP timeout: 60s per request\n",
      "--------------------------------------------------\n",
      "  Facts 1: + Generating\n",
      "    Context: Albert Einstein > Introduction\n",
      "    Input: • Albert Einstein was born on 14 March 1879 in the German Empire. • Albert Einst...\n",
      "    [Calling LLM with schema tools...] ✓ (2684 chars, 30.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 2: + Generating\n",
      "    Context: Albert Einstein > Introduction\n",
      "    Input: • In 1905, Albert Einstein published four groundbreaking papers that outlined a ...\n",
      "    [Calling LLM with schema tools...] ✓ (6946 chars, 46.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 3: + Generating\n",
      "    Context: Albert Einstein > Life and career\n",
      "    Input: • Albert Einstein was born in Ulm, in the Kingdom of Württemberg in the German E...\n",
      "    [Calling LLM with schema tools...] ✓ (2226 chars, 22.1s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 4: + Generating\n",
      "    Context: Albert Einstein > Life and career > Childhood, youth and education\n",
      "    Input: • In 1894, Hermann and Jakob's company tendered for a contract to install electr...\n",
      "    [Calling LLM with schema tools...] ✓ (2803 chars, 29.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 5: + Generating\n",
      "    Context: Albert Einstein > Life and career > Childhood, youth and education\n",
      "    Input: • Albert Einstein excelled at physics and mathematics from an early age. • Alber...\n",
      "    [Calling LLM with schema tools...] ✓ (5146 chars, 26.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 6: + Generating\n",
      "    Context: Albert Einstein > Life and career > Childhood, youth and education\n",
      "    Input: • Albert Einstein was thirteen years old when he was introduced to Kant's Critiq...\n",
      "    [Calling LLM with schema tools...] ✓ (4329 chars, 22.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 7: + Generating\n",
      "    Context: Albert Einstein > Life and career > Childhood, youth and education\n",
      "    Input: • In January 1896, Albert Einstein renounced his citizenship of the German Kingd...\n",
      "    [Calling LLM with schema tools...] ✓ (72 chars, 11.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 8: + Generating\n",
      "    Context: Albert Einstein > Life and career > Marriages, relationships and children\n",
      "    Input: - Albert Einstein and Mileva Marić had a daughter named Lieserl in early 1902. -...\n",
      "    [Calling LLM with schema tools...] ✓ (3936 chars, 37.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 9: + Generating\n",
      "    Context: Albert Einstein > Life and career > Marriages, relationships and children\n",
      "    Input: • Albert Einstein was married to Mileva Marić from 1903 to 1919. • Albert Einste...\n",
      "    [Calling LLM with schema tools...] ✓ (72 chars, 36.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 10: + Generating\n",
      "    Context: Albert Einstein > Life and career > Assistant at the Swiss Patent Office (1902–1909)\n",
      "    Input: • Albert Einstein graduated from the federal polytechnic school in 1900 and was ...\n",
      "    [Calling LLM with schema tools...] ✓ (73 chars, 9.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 11: + Generating\n",
      "    Context: Albert Einstein > Life and career > First scientific papers (1900–1905)\n",
      "    Input: - Albert Einstein's first scientific paper, titled \"Folgerungen aus den Capillar...\n",
      "    [Calling LLM with schema tools...] ✗ APITimeoutError after 82.3s\n",
      "    Error: Request timed out.\n",
      "    [Saving notebook...] saved\n",
      "  Facts 12: + Generating\n",
      "    Context: Albert Einstein > Life and career > Academic career in Europe (1908–1933)\n",
      "    Input: • Albert Einstein attended the first Solvay Conference on Physics from 30 Octobe...\n",
      "    [Calling LLM with schema tools...] ✓ (9086 chars, 58.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 13: + Generating\n",
      "    Context: Albert Einstein > Life and career > Academic career in Europe (1908–1933)\n",
      "    Input: • Albert Einstein was elected president of the German Physical Society in 1916. ...\n",
      "    [Calling LLM with schema tools...] ✓ (4757 chars, 30.8s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 14: + Generating\n",
      "    Context: Albert Einstein > Life and career > Academic career in Europe (1908–1933)\n",
      "    Input: • Albert Einstein resigned from the Prussian Academy in March 1933. • Albert Ein...\n",
      "    [Calling LLM with schema tools...] ✓ (730 chars, 18.1s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 15: + Generating\n",
      "    Context: Albert Einstein > Life and career > Putting general relativity to the test (1919)\n",
      "    Input: • In 1907, Albert Einstein formulated the equivalence principle, which states th...\n",
      "    [Calling LLM with schema tools...] ✓ (3557 chars, 30.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 16: + Generating\n",
      "    Context: Albert Einstein > Life and career > Coming to terms with fame (1921–1923)\n",
      "    Input: • Albert Einstein became \"perhaps the world's first celebrity scientist\" after E...\n",
      "    [Calling LLM with schema tools...] ✓ (3455 chars, 50.1s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 17: + Generating\n",
      "    Context: Albert Einstein > Life and career > Coming to terms with fame (1921–1923)\n",
      "    Input: • In 1922, Albert Einstein undertook a six-month tour of Asia. • During his Asia...\n",
      "    [Calling LLM with schema tools...] ✓ (4582 chars, 31.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 18: + Generating\n",
      "    Context: Albert Einstein > Life and career > Coming to terms with fame (1921–1923)\n",
      "    Input: • Albert Einstein decided to tour the eastern hemisphere in 1922 • Albert Einste...\n",
      "    [Calling LLM with schema tools...] ✓ (79 chars, 9.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 19: + Generating\n",
      "    Context: Albert Einstein > Life and career > Serving the League of Nations (1922–1932)\n",
      "    Input: • Albert Einstein was a member of the International Committee on Intellectual Co...\n",
      "    [Calling LLM with schema tools...] ✓ (6677 chars, 41.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 20: + Generating\n",
      "    Context: Albert Einstein > Life and career > Touring the US (1930–1931)\n",
      "    Input: • Albert Einstein began a significant sojourn in the United States in December 1...\n",
      "    [Calling LLM with schema tools...] ✓ (4185 chars, 31.2s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 21: + Generating\n",
      "    Context: Albert Einstein > Life and career > Touring the US (1930–1931)\n",
      "    Input: • Albert Einstein traveled to California in 1930–1931. • In California, Albert E...\n",
      "    [Calling LLM with schema tools...] ✓ (6586 chars, 50.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 22: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933)\n",
      "    Input: • Albert Einstein was in the United States in February 1933 while on a visit • A...\n",
      "    [Calling LLM with schema tools...] ✓ (93 chars, 11.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 23: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > Refugee status\n",
      "    Input: • In April 1933, Albert Einstein discovered that the new German government had p...\n",
      "    [Calling LLM with schema tools...] ✓ (151 chars, 35.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 24: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > Refugee status\n",
      "    Input: • Albert Einstein was without a permanent home and unsure where he would live an...\n",
      "    [Calling LLM with schema tools...] ✓ (3499 chars, 37.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 25: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > Refugee status\n",
      "    Input: • Albert Einstein contacted British leaders including Winston Churchill, Austen ...\n",
      "    [Calling LLM with schema tools...] ✓ (5251 chars, 46.6s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 26: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > Resident scholar at the Institute for Advanced Study\n",
      "    Input: • Albert Einstein delivered a speech on academic freedom at the Royal Albert Hal...\n",
      "    [Calling LLM with schema tools...] ✗ APITimeoutError after 73.1s\n",
      "    Error: Request timed out.\n",
      "    [Saving notebook...] saved\n",
      "  Facts 27: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > World War II and the Manhattan Project\n",
      "    Input: • In 1939, a group of Hungarian scientists including physicist Leó Szilárd attem...\n",
      "    [Calling LLM with schema tools...] ✓ (6571 chars, 35.6s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 28: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > World War II and the Manhattan Project\n",
      "    Input: • Albert Einstein called war a disease and advocated for resistance to war. • Al...\n",
      "    [Calling LLM with schema tools...] ✓ (3699 chars, 26.2s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 29: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > US citizenship\n",
      "    Input: • Albert Einstein became a naturalized citizen of the United States in 1940. • A...\n",
      "    [Calling LLM with schema tools...] ✓ (4174 chars, 34.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 30: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > US citizenship\n",
      "    Input: • Albert Einstein became an American citizen in 1940 • Albert Einstein settled i...\n",
      "    [Calling LLM with schema tools...] ✓ (83 chars, 10.6s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 31: + Generating\n",
      "    Context: Albert Einstein > Life and career > Emigration to the US (1933) > US citizenship\n",
      "    Input: • In 1946, Albert Einstein visited Lincoln University in Pennsylvania. • Lincoln...\n",
      "    [Calling LLM with schema tools...] ✓ (8387 chars, 51.8s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 32: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views\n",
      "    Input: • Albert Einstein was one of the signatories of the founding proclamation of the...\n",
      "    [Calling LLM with schema tools...] ✓ (906 chars, 19.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 33: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views > Political views\n",
      "    Input: • Albert Einstein honored Lenin as a man who sacrificed himself for social justi...\n",
      "    [Calling LLM with schema tools...] ✓ (81 chars, 11.9s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 34: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views > Relationship with Zionism\n",
      "    Input: • Albert Einstein was a figurehead leader in the establishment of the Hebrew Uni...\n",
      "    [Calling LLM with schema tools...] ✗ APITimeoutError after 74.7s\n",
      "    Error: Request timed out.\n",
      "    [Saving notebook...] saved\n",
      "  Facts 35: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views > Religious and philosophical views\n",
      "    Input: • Albert Einstein said he had sympathy for the impersonal pantheistic God of Bar...\n",
      "    [Calling LLM with schema tools...] ✓ (3568 chars, 30.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 36: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views > Religious and philosophical views\n",
      "    Input: • Albert Einstein believed that the word God represents human weaknesses and tha...\n",
      "    [Calling LLM with schema tools...] ✓ (126 chars, 10.8s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 37: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views > Love of music\n",
      "    Input: • Albert Einstein said \"If I were not a physicist, I would probably be a musicia...\n",
      "    [Calling LLM with schema tools...] ✓ (2159 chars, 34.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 38: + Generating\n",
      "    Context: Albert Einstein > Life and career > Personal views > Love of music\n",
      "    Input: • Music became a pivotal and permanent part of Albert Einstein's life. • Einstei...\n",
      "    [Calling LLM with schema tools...] ✓ (2570 chars, 22.0s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 39: + Generating\n",
      "    Context: Albert Einstein > Life and career > Death\n",
      "    Input: • Albert Einstein died on 17 April 1955 at the age of 76. • Einstein died from i...\n",
      "    [Calling LLM with schema tools...] ✓ (4459 chars, 29.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 40: + Generating\n",
      "    Context: Albert Einstein > Scientific career\n",
      "    Input: • Albert Einstein published more than 300 scientific papers and 150 non-scientif...\n",
      "    [Calling LLM with schema tools...] ✓ (63 chars, 10.1s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 41: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Statistical mechanics > Theory of critical opalescence\n",
      "    Input: • Albert Einstein returned to the problem of thermodynamic fluctuations and gave...\n",
      "    [Calling LLM with schema tools...] ✓ (3864 chars, 30.8s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 42: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Special relativity\n",
      "    Input: • Albert Einstein's paper \"On the Electrodynamics of Moving Bodies\" was received...\n",
      "    [Calling LLM with schema tools...] ✓ (3957 chars, 26.9s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 43: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity\n",
      "    Input: • General relativity is a theory of gravitation developed by Albert Einstein bet...\n",
      "    [Calling LLM with schema tools...] ✓ (4802 chars, 27.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 44: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity > Gravitational waves\n",
      "    Input: • In 1916, Albert Einstein predicted gravitational waves as ripples in the curva...\n",
      "    [Calling LLM with schema tools...] ✓ (3635 chars, 26.8s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 45: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity > Physical cosmology\n",
      "    Input: • In 1917, Albert Einstein applied the general theory of relativity to the struc...\n",
      "    [Calling LLM with schema tools...] ✓ (3495 chars, 30.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 46: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity > Physical cosmology\n",
      "    Input: • In late 2013, a team led by the Irish physicist Cormac O'Raifeartaigh discover...\n",
      "    [Calling LLM with schema tools...] ✓ (92 chars, 11.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 47: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity > Energy momentum pseudotensor\n",
      "    Input: • Albert Einstein argued that energy and momentum in a gravitational field canno...\n",
      "    [Calling LLM with schema tools...] ✓ (129 chars, 11.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 48: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity > Einstein–Cartan theory\n",
      "    Input: • Albert Einstein and Élie Cartan modified general relativity in the 1920s by ge...\n",
      "    [Calling LLM with schema tools...] ✓ (1899 chars, 14.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 49: + Generating\n",
      "    Context: Albert Einstein > Scientific career > General relativity > Equations of motion\n",
      "    Input: • Albert Einstein proposed that the field equations of general relativity would ...\n",
      "    [Calling LLM with schema tools...] ✓ (4004 chars, 25.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 50: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Old quantum theory\n",
      "    Input: • In 1905, Albert Einstein postulated that light itself consists of localized pa...\n",
      "    [Calling LLM with schema tools...] ✓ (4542 chars, 29.3s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 51: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Old quantum theory > Bose–Einstein statistics\n",
      "    Input: - In 1924, Albert Einstein received a description of a statistical model from In...\n",
      "    [Calling LLM with schema tools...] ✗ APITimeoutError after 95.0s\n",
      "    Error: Request timed out.\n",
      "    [Saving notebook...] saved\n",
      "  Facts 52: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Old quantum theory > Zero-point energy\n",
      "    Input: • In a series of works completed from 1911 to 1913, Max Planck reformulated his ...\n",
      "    [Calling LLM with schema tools...] ✗ APITimeoutError after 72.8s\n",
      "    Error: Request timed out.\n",
      "    [Saving notebook...] saved\n",
      "  Facts 53: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Quantum mechanics\n",
      "    Input: • Albert Einstein played a major role in developing quantum theory beginning wit...\n",
      "    [Calling LLM with schema tools...] ✓ (2019 chars, 25.2s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 54: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Quantum mechanics > Einstein–Podolsky–Rosen paradox\n",
      "    Input: • Albert Einstein never fully accepted quantum mechanics. • Einstein recognized ...\n",
      "    [Calling LLM with schema tools...] ✓ (4699 chars, 35.9s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 55: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Quantum mechanics > Einstein–Podolsky–Rosen paradox\n",
      "    Input: • Albert Einstein published a paper in 1935 with Boris Podolsky and Nathan Rosen...\n",
      "    [Calling LLM with schema tools...] ✓ (4292 chars, 26.9s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 56: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Quantum mechanics > Einstein–Podolsky–Rosen paradox\n",
      "    Input: • John Stewart Bell carried the analysis of quantum entanglement further in 1964...\n",
      "    [Calling LLM with schema tools...] ✓ (3247 chars, 23.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 57: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Unified field theory\n",
      "    Input: • Albert Einstein sought an ambitious geometrical theory that would treat gravit...\n",
      "    [Calling LLM with schema tools...] ✓ (3124 chars, 38.6s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 58: + Generating\n",
      "    Context: Albert Einstein > Scientific career > Collaboration with other scientists > Einstein–de Haas experiment\n",
      "    Input: - Owen Willans Richardson predicted in 1908 that a change in the magnetic moment...\n",
      "    [Calling LLM with schema tools...] ✓ (119 chars, 10.2s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 59: + Generating\n",
      "    Context: Albert Einstein > Legacy\n",
      "    Input: - Albert Einstein wrote daily letters to his wife Elsa and adopted stepdaughters...\n",
      "    [Calling LLM with schema tools...] ✗ APITimeoutError after 77.7s\n",
      "    Error: Request timed out.\n",
      "    [Saving notebook...] saved\n",
      "  Facts 60: + Generating\n",
      "    Context: Albert Einstein > Legacy > Scientific\n",
      "    Input: • In 1999, a survey of top physicists voted Albert Einstein as the \"greatest phy...\n",
      "    [Calling LLM with schema tools...] ✓ (5623 chars, 32.7s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 61: + Generating\n",
      "    Context: Albert Einstein > In popular culture\n",
      "    Input: • Albert Einstein became one of the most famous scientific celebrities after the...\n",
      "    [Calling LLM with schema tools...] ✓ (59 chars, 10.4s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 62: + Generating\n",
      "    Context: Albert Einstein > Publications\n",
      "    Input: - Albert Einstein co-authored an article titled \"To the editors of The New York ...\n",
      "    [Calling LLM with schema tools...] ✓ (6912 chars, 38.5s)\n",
      "    [Saving notebook...] saved\n",
      "  Facts 63: + Generating\n",
      "    Context: Albert Einstein > External links > Archival materials collections\n",
      "    Input: • Albert Einstein's Historical Letters, Documents & Papers are held at the Shape...\n",
      "    [Calling LLM with schema tools...] ✓ (13914 chars, 65.3s)\n",
      "    [Saving notebook...] saved\n",
      "--------------------------------------------------\n",
      "RDF generation complete:\n",
      "  - 57 generated\n",
      "  - 0 skipped (up-to-date)\n",
      "  - 6 errors/timeouts\n"
     ]
    }
   ],
   "source": [
    "# Load schema matcher with pre-built vocabulary index\n",
    "from schema_matcher import SchemaMatcher\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "VOCAB_CACHE_DIR = \"data/vocab_cache\"\n",
    "schema_matcher = SchemaMatcher.load(VOCAB_CACHE_DIR, embed_base_url=LLM_CONFIG[\"base_url\"])\n",
    "log_progress(f\"Loaded schema matcher with {len(schema_matcher.vocabularies)} vocabularies\")\n",
    "\n",
    "# Define tools for the LLM to query schema.org vocabulary\n",
    "\n",
    "@tool\n",
    "def find_rdf_class(description: str) -> str:\n",
    "    \"\"\"Find the best schema.org class/type for an entity based on a natural language description.\n",
    "    \n",
    "    Use this when you need to determine the rdf:type of an entity.\n",
    "    Example: find_rdf_class(\"a person who does scientific research\")\n",
    "    \n",
    "    Args:\n",
    "        description: Natural language description of the entity type\n",
    "    \n",
    "    Returns:\n",
    "        Top matching schema.org classes with URIs and descriptions\n",
    "    \"\"\"\n",
    "    results = schema_matcher.find_class(description, top_k=5)\n",
    "    if not results:\n",
    "        return \"No matches found. Use a generic type like schema:Thing\"\n",
    "    \n",
    "    lines = [\"Top matching classes:\"]\n",
    "    for r in results:\n",
    "        lines.append(f\"  {r['prefix']} ({r['score']:.2f})\")\n",
    "        lines.append(f\"    URI: {r['uri']}\")\n",
    "        if r['description']:\n",
    "            lines.append(f\"    Description: {r['description'][:100]}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "@tool\n",
    "def find_rdf_property(description: str, subject_type: str = \"\", object_type: str = \"\") -> str:\n",
    "    \"\"\"Find the best schema.org property/predicate for a relationship.\n",
    "    \n",
    "    Use this when you need to find the right predicate for a triple.\n",
    "    Example: find_rdf_property(\"the date when someone was born\", subject_type=\"Person\")\n",
    "    \n",
    "    Args:\n",
    "        description: Natural language description of the relationship\n",
    "        subject_type: Optional - the type of the subject (e.g., \"Person\", \"Organization\")  \n",
    "        object_type: Optional - the type of the object/value (e.g., \"Date\", \"Place\")\n",
    "    \n",
    "    Returns:\n",
    "        Top matching schema.org properties with URIs, domains, and ranges\n",
    "    \"\"\"\n",
    "    results = schema_matcher.find_property(\n",
    "        description, \n",
    "        subject_type=subject_type or None,\n",
    "        object_type=object_type or None,\n",
    "        top_k=5\n",
    "    )\n",
    "    if not results:\n",
    "        return \"No matches found. Consider using rdfs:label or a descriptive URI fragment.\"\n",
    "    \n",
    "    lines = [\"Top matching properties:\"]\n",
    "    for r in results:\n",
    "        lines.append(f\"  {r['prefix']} ({r['score']:.2f})\")\n",
    "        lines.append(f\"    URI: {r['uri']}\")\n",
    "        if r['domain']:\n",
    "            lines.append(f\"    Domain: {r['domain']}\")\n",
    "        if r['range']:\n",
    "            lines.append(f\"    Range: {r['range']}\")\n",
    "        if r['description']:\n",
    "            lines.append(f\"    Description: {r['description'][:80]}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Create LLM client with timeout\n",
    "rdf_llm = ChatOpenAI(\n",
    "    model=LLM_CONFIG[\"model\"],\n",
    "    temperature=LLM_CONFIG[\"temperature\"],\n",
    "    base_url=LLM_CONFIG[\"base_url\"],\n",
    "    api_key=\"lm-studio\",  # type: ignore\n",
    "    timeout=CELL_TIMEOUT_SECONDS,\n",
    "    max_retries=0,\n",
    ")\n",
    "\n",
    "# Bind tools to the LLM for tool calling\n",
    "rdf_tools = [find_rdf_class, find_rdf_property]\n",
    "rdf_llm_with_tools = rdf_llm.bind_tools(rdf_tools)\n",
    "\n",
    "# Create RDF generation prompt\n",
    "rdf_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert at converting factual statements to RDF triples in Turtle format.\n",
    "\n",
    "You have access to tools to find correct schema.org vocabulary:\n",
    "- find_rdf_class: Find the best class/type for an entity\n",
    "- find_rdf_property: Find the best predicate for a relationship\n",
    "\n",
    "IMPORTANT: Use these tools to look up appropriate schema.org terms. Do NOT invent predicates.\n",
    "\n",
    "Generate valid Turtle RDF triples. Use schema.org prefixed terms (e.g., schema:Person, schema:birthDate).\"\"\"),\n",
    "    (\"human\", \"\"\"Convert these factual statements to RDF triples.\n",
    "\n",
    "Source: {source_url}\n",
    "Section context: {breadcrumb}\n",
    "\n",
    "Entity Registry (use these URIs for known entities):\n",
    "{entity_registry}\n",
    "\n",
    "Factual statements to convert:\n",
    "{facts}\n",
    "\n",
    "Use the tools to find appropriate schema.org classes and properties, then generate the Turtle RDF.\"\"\"),\n",
    "])\n",
    "\n",
    "# Simple tool-calling loop instead of agent framework\n",
    "def call_llm_with_tools(prompt_vars: dict, max_iterations: int = 10) -> str:\n",
    "    \"\"\"Call LLM with tool support using a simple loop.\"\"\"\n",
    "    messages = rdf_prompt.format_messages(**prompt_vars)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        response = rdf_llm_with_tools.invoke(messages)\n",
    "        \n",
    "        # Check if there are tool calls\n",
    "        if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "            # Add assistant message with tool calls\n",
    "            messages.append(response)\n",
    "            \n",
    "            # Execute each tool call\n",
    "            for tool_call in response.tool_calls:\n",
    "                tool_name = tool_call['name']\n",
    "                tool_args = tool_call['args']\n",
    "                \n",
    "                # Find and execute the tool\n",
    "                if tool_name == 'find_rdf_class':\n",
    "                    tool_result = find_rdf_class.invoke(tool_args)\n",
    "                elif tool_name == 'find_rdf_property':\n",
    "                    tool_result = find_rdf_property.invoke(tool_args)\n",
    "                else:\n",
    "                    tool_result = f\"Unknown tool: {tool_name}\"\n",
    "                \n",
    "                # Add tool result message\n",
    "                from langchain_core.messages import ToolMessage\n",
    "                messages.append(ToolMessage(content=str(tool_result), tool_call_id=tool_call['id']))\n",
    "        else:\n",
    "            # No tool calls, return the content\n",
    "            return response.content\n",
    "    \n",
    "    # Max iterations reached\n",
    "    return response.content if hasattr(response, 'content') else str(response)\n",
    "\n",
    "def format_entity_registry_for_prompt(registry: EntityRegistry) -> str:\n",
    "    \"\"\"Format registry for RDF prompt.\"\"\"\n",
    "    lines = []\n",
    "    for entity in registry.entities.values():\n",
    "        lines.append(f\"<{entity['uri']}> # {entity['label']} ({entity['type']})\")\n",
    "    return \"\\n\".join(lines) if lines else \"# No entities registered yet\"\n",
    "\n",
    "# Read facts notebook to get source content and CIDs\n",
    "log_progress(\"Reading facts notebook...\")\n",
    "facts_nb = nbformat.read(facts_path, as_version=4)\n",
    "facts_signatures = extract_signatures(facts_nb)\n",
    "\n",
    "# Build list of facts content with CIDs\n",
    "facts_data = []\n",
    "cell_idx = 2  # Skip provenance and registry\n",
    "while cell_idx < len(facts_nb.cells):\n",
    "    cell = facts_nb.cells[cell_idx]\n",
    "    if cell.cell_type == 'markdown':\n",
    "        content = cell.source\n",
    "        # Get corresponding signature (next cell)\n",
    "        sig = None\n",
    "        if cell_idx + 1 < len(facts_nb.cells):\n",
    "            sig = parse_signature(facts_nb.cells[cell_idx + 1].source)\n",
    "        \n",
    "        # Extract breadcrumb\n",
    "        context_match = re.search(r'\\*\\*Context:\\*\\*\\s*(.+)', content)\n",
    "        breadcrumb = context_match.group(1) if context_match else \"Unknown\"\n",
    "        \n",
    "        # Extract facts (after ---)\n",
    "        parts = content.split(\"---\\n\", 1)\n",
    "        facts_text = parts[1].strip() if len(parts) > 1 else content\n",
    "        \n",
    "        facts_data.append({\n",
    "            \"cell_num\": sig[\"cell\"] if sig else len(facts_data) + 1,\n",
    "            \"content\": content,\n",
    "            \"facts_text\": facts_text,\n",
    "            \"breadcrumb\": breadcrumb,\n",
    "            \"cid\": sig[\"cid\"] if sig else compute_cid(content),\n",
    "        })\n",
    "        cell_idx += 2  # Skip content and signature\n",
    "    else:\n",
    "        cell_idx += 1\n",
    "\n",
    "log_progress(f\"Found {len(facts_data)} facts cells with CIDs\")\n",
    "\n",
    "# Read existing RDF notebook and extract signatures\n",
    "rdf_nb = nbformat.read(rdf_path, as_version=4)\n",
    "rdf_signatures = extract_signatures(rdf_nb)\n",
    "\n",
    "log_progress(f\"Found {len(rdf_signatures)} existing RDF signatures\")\n",
    "log_progress(f\"HTTP timeout: {CELL_TIMEOUT_SECONDS}s per request\")\n",
    "log_progress(\"-\" * 50)\n",
    "\n",
    "# Process each facts cell\n",
    "processed_count = 0\n",
    "skipped_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for facts_item in facts_data:\n",
    "    cell_num = facts_item[\"cell_num\"]\n",
    "    source_cid = facts_item[\"cid\"]\n",
    "    \n",
    "    # Skip cells that had errors in facts extraction\n",
    "    if facts_item[\"facts_text\"].startswith(\"# Error:\"):\n",
    "        log_progress(f\"  Facts {cell_num}: ⊘ Source had error, skipping\")\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Check if we already have up-to-date RDF for these facts\n",
    "    existing_sig = rdf_signatures.get(cell_num)\n",
    "    if existing_sig and existing_sig[\"from_cid\"] == source_cid:\n",
    "        log_progress(f\"  Facts {cell_num}: ⊘ Up-to-date (CID match), skipping\")\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Need to generate (or regenerate) this cell\n",
    "    status = \"↻ Regenerating\" if existing_sig else \"+ Generating\"\n",
    "    facts_preview = facts_item[\"facts_text\"][:80].replace('\\n', ' ')\n",
    "    log_progress(f\"  Facts {cell_num}: {status}\")\n",
    "    log_progress(f\"    Context: {facts_item['breadcrumb']}\")\n",
    "    log_progress(f\"    Input: {facts_preview}...\")\n",
    "    log_progress(f\"    [Calling LLM with schema tools...]\", end=\" \")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Call LLM with tool support\n",
    "    try:\n",
    "        rdf_content = call_llm_with_tools({\n",
    "            \"source_url\": provenance[\"source_url\"],\n",
    "            \"breadcrumb\": facts_item[\"breadcrumb\"],\n",
    "            \"entity_registry\": format_entity_registry_for_prompt(registry),\n",
    "            \"facts\": facts_item[\"facts_text\"],\n",
    "        })\n",
    "        elapsed = time.time() - start_time\n",
    "        log_progress(f\"✓ ({len(rdf_content)} chars, {elapsed:.1f}s)\")\n",
    "        processed_count += 1\n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - start_time\n",
    "        error_type = type(e).__name__\n",
    "        error_msg = str(e)[:100]\n",
    "        rdf_content = f\"# Error: {error_type}: {e}\"\n",
    "        log_progress(f\"✗ {error_type} after {elapsed:.1f}s\")\n",
    "        log_progress(f\"    Error: {error_msg}\")\n",
    "        error_count += 1\n",
    "    \n",
    "    # Build the RDF cell content\n",
    "    rdf_cell_content = f\"\"\"# Context: {facts_item['breadcrumb']}\n",
    "# Cell: {cell_num} of {len(facts_data)}\n",
    "\n",
    "{rdf_content}\n",
    "\"\"\"\n",
    "    rdf_cid = compute_cid(rdf_cell_content)\n",
    "    signature = make_signature(cell_num, \"rdf\", rdf_cid, source_cid)\n",
    "    \n",
    "    # Find where to insert/update in the notebook\n",
    "    # If there's an existing signature for this cell, find and remove old content+sig\n",
    "    if existing_sig:\n",
    "        # Find and remove the old cells\n",
    "        new_cells = [rdf_nb.cells[0], rdf_nb.cells[1]]  # Keep header\n",
    "        i = 2\n",
    "        while i < len(rdf_nb.cells):\n",
    "            cell = rdf_nb.cells[i]\n",
    "            if cell.cell_type == 'raw':\n",
    "                sig = parse_signature(cell.source)\n",
    "                if sig and sig[\"cell\"] == cell_num:\n",
    "                    # Skip this signature and its preceding content cell\n",
    "                    i += 1\n",
    "                    continue\n",
    "            # Check if this is content for the cell we're replacing\n",
    "            if i > 0 and i + 1 < len(rdf_nb.cells):\n",
    "                next_sig = parse_signature(rdf_nb.cells[i + 1].source) if rdf_nb.cells[i + 1].cell_type == 'raw' else None\n",
    "                if next_sig and next_sig[\"cell\"] == cell_num:\n",
    "                    i += 2  # Skip content and signature\n",
    "                    continue\n",
    "            new_cells.append(cell)\n",
    "            i += 1\n",
    "        rdf_nb.cells = new_cells\n",
    "    \n",
    "    # Append new content and signature\n",
    "    rdf_nb.cells.append(new_raw_cell(rdf_cell_content))\n",
    "    rdf_nb.cells.append(new_raw_cell(json.dumps(signature)))\n",
    "    \n",
    "    # Update signatures dict\n",
    "    rdf_signatures[cell_num] = signature\n",
    "    \n",
    "    # Save notebook after each cell\n",
    "    log_progress(f\"    [Saving notebook...]\", end=\" \")\n",
    "    with open(rdf_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(rdf_nb, f)\n",
    "    log_progress(\"saved\")\n",
    "\n",
    "log_progress(\"-\" * 50)\n",
    "log_progress(f\"RDF generation complete:\")\n",
    "log_progress(f\"  - {processed_count} generated\")\n",
    "log_progress(f\"  - {skipped_count} skipped (up-to-date)\")\n",
    "log_progress(f\"  - {error_count} errors/timeouts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de69a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF notebook: data/albert_einstein_rdf.ipynb\n",
      "  - Updated incrementally during processing\n",
      "  - Ready for review/editing before final export\n"
     ]
    }
   ],
   "source": [
    "# Summary of RDF generation (notebook already updated incrementally)\n",
    "print(f\"RDF notebook: {rdf_path}\")\n",
    "print(f\"  - Updated incrementally during processing\")\n",
    "print(f\"  - Ready for review/editing before final export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373a59d9",
   "metadata": {},
   "source": [
    "## Export Combined RDF\n",
    "\n",
    "Combine all RDF cells into a single Turtle file with prefixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d061083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported RDF to: data/albert_einstein.ttl\n",
      "  - 57 chunks of triples\n",
      "  - 198405 characters total\n"
     ]
    }
   ],
   "source": [
    "# Combine all RDF into a single Turtle file\n",
    "all_triples = []\n",
    "\n",
    "# Read the updated RDF notebook\n",
    "rdf_nb = nbformat.read(rdf_path, as_version=4)\n",
    "\n",
    "# Collect RDF from all raw cells (skip provenance, registry, and signature cells)\n",
    "for cell in rdf_nb.cells[2:]:\n",
    "    if cell.cell_type == 'raw':\n",
    "        content = cell.source.strip()\n",
    "        \n",
    "        # Skip signature cells (JSON objects)\n",
    "        if content.startswith('{') and '\"cid\"' in content:\n",
    "            continue\n",
    "        \n",
    "        # Skip empty or error-only cells\n",
    "        if not content or content.startswith('# Error:'):\n",
    "            continue\n",
    "        \n",
    "        # Skip comment-only cells\n",
    "        lines = [line for line in content.split('\\n') \n",
    "                 if line.strip() and not line.strip().startswith('#')]\n",
    "        if lines:\n",
    "            all_triples.append(content)\n",
    "\n",
    "# Format prefixes for the Turtle file\n",
    "turtle_prefixes = RDF_PREFIXES.format(source_url=provenance['source_url'])\n",
    "\n",
    "# Build complete Turtle file\n",
    "turtle_output = f\"\"\"# RDF Knowledge Graph: {provenance['article_title']}\n",
    "# Source: {provenance['source_url']}\n",
    "# License: {provenance['license']}\n",
    "# Generated: {datetime.now().isoformat()}\n",
    "\n",
    "{turtle_prefixes}\n",
    "\n",
    "# === Triples ===\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "turtle_output += \"\\n\\n\".join(all_triples)\n",
    "\n",
    "# Save to file\n",
    "turtle_path = os.path.join(OUTPUT_DIR, f\"{article_slug}.ttl\")\n",
    "with open(turtle_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(turtle_output)\n",
    "\n",
    "print(f\"Exported RDF to: {turtle_path}\")\n",
    "print(f\"  - {len(all_triples)} chunks of triples\")\n",
    "print(f\"  - {len(turtle_output)} characters total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7c4e37",
   "metadata": {},
   "source": [
    "## Save Initial Entity Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d416a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/entity_registry.json\n",
      "\n",
      "Initial entities: 1\n",
      "  - Albert Einstein (Person): https://en.wikipedia.org/wiki/Albert_Einstein#person_albert_einstein\n"
     ]
    }
   ],
   "source": [
    "# Save entity registry to JSON file\n",
    "registry_path = os.path.join(OUTPUT_DIR, \"entity_registry.json\")\n",
    "with open(registry_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(registry.to_json())\n",
    "\n",
    "print(f\"Saved: {registry_path}\")\n",
    "print(f\"\\nInitial entities: {len(registry.entities)}\")\n",
    "for key, entity in registry.entities.items():\n",
    "    print(f\"  - {entity['label']} ({entity['type']}): {entity['uri']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2368a",
   "metadata": {},
   "source": [
    "## Pipeline Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b31bf97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PIPELINE COMPLETE\n",
      "============================================================\n",
      "\n",
      "Article: Albert Einstein\n",
      "Source: https://en.wikipedia.org/wiki/Albert_Einstein\n",
      "License: CC BY-SA 4.0\n",
      "\n",
      "Generated artifacts:\n",
      "  1. data/albert_einstein_chunks.ipynb\n",
      "     - 63 chunks with breadcrumb context\n",
      "  2. data/albert_einstein_facts.ipynb\n",
      "     - Facts extracted from chunks (see notebook for details)\n",
      "  3. data/albert_einstein_rdf.ipynb\n",
      "     - RDF triples generated from facts (see notebook for details)\n",
      "  4. data/albert_einstein.ttl\n",
      "     - Combined Turtle file for import\n",
      "\n",
      "Entity registry: data/entity_registry.json\n",
      "\n",
      "The intermediate notebooks can be reviewed and edited before re-export.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PIPELINE COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nArticle: {ARTICLE_TITLE}\")\n",
    "print(f\"Source: {source_url}\")\n",
    "print(f\"License: {provenance['license']}\")\n",
    "print(f\"\\nGenerated artifacts:\")\n",
    "print(f\"  1. {chunks_path}\")\n",
    "print(f\"     - {len(contextual_chunks)} chunks with breadcrumb context\")\n",
    "print(f\"  2. {facts_path}\")\n",
    "print(f\"     - Facts extracted from chunks (see notebook for details)\")\n",
    "print(f\"  3. {rdf_path}\")\n",
    "print(f\"     - RDF triples generated from facts (see notebook for details)\")\n",
    "print(f\"  4. {turtle_path}\")\n",
    "print(f\"     - Combined Turtle file for import\")\n",
    "print(f\"\\nEntity registry: {registry_path}\")\n",
    "print(f\"\\nThe intermediate notebooks can be reviewed and edited before re-export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef4bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
