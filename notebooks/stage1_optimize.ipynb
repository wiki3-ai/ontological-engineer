{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48be6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/workspaces/wiki3-kg-project')\n",
    "\n",
    "import dspy\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from ontological_engineer import (\n",
    "    configure_lm,\n",
    "    StatementExtractor,\n",
    "    StatementQualityJudge,\n",
    ")\n",
    "from ontological_engineer.judges import statement_quality_metric\n",
    "from ontological_engineer.training import (\n",
    "    load_stage1_config,\n",
    "    load_trainset,\n",
    "    load_devset,\n",
    "    load_fewshot_examples,\n",
    "    save_optimized_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500a0e1",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Artifacts\n",
    "\n",
    "Load the config and datasets saved by `stage1_statements.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff934464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stage1 config (saved with CID provenance)\n",
    "training_dir = Path(\"/workspaces/wiki3-kg-project/data/training\")\n",
    "\n",
    "config = load_stage1_config(training_dir)\n",
    "print(f\"Loaded config:\")\n",
    "print(f\"  Model: {config['model']}\")\n",
    "print(f\"  API base: {config['api_base']}\")\n",
    "print(f\"  Temperature: {config['temperature']}\")\n",
    "print(f\"  Num fewshot: {config['num_fewshot']}\")\n",
    "print(f\"  Config CID: {config.get('cid', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LM from saved config\n",
    "lm = configure_lm(\n",
    "    model=config['model'],\n",
    "    api_base=config['api_base'],\n",
    "    temperature=config['temperature'],\n",
    ")\n",
    "print(f\"Configured LM: {lm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e374bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and dev sets (with provenance)\n",
    "trainset = load_trainset(training_dir)\n",
    "devset = load_devset(training_dir)\n",
    "\n",
    "print(f\"Loaded trainset: {len(trainset)} examples\")\n",
    "print(f\"Loaded devset: {len(devset)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27019b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load few-shot examples\n",
    "fewshot_examples = load_fewshot_examples(training_dir)\n",
    "print(f\"Loaded {len(fewshot_examples)} few-shot examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86eda37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline results for comparison\n",
    "baseline_path = training_dir / \"baseline_results.json\"\n",
    "if baseline_path.exists():\n",
    "    with open(baseline_path) as f:\n",
    "        baseline_results = json.load(f)\n",
    "    baseline_score = baseline_results['score']\n",
    "    print(f\"Baseline score: {baseline_score:.2f}\")\n",
    "    print(f\"Baseline CID: {baseline_results.get('cid', 'N/A')}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No baseline results found. Run stage1_statements.ipynb first.\")\n",
    "    baseline_score = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a483ef",
   "metadata": {},
   "source": [
    "## 2. MLflow Setup\n",
    "\n",
    "Configure MLflow for optimization tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"http://127.0.0.1:5000\"\n",
    "\n",
    "try:\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    mlflow.set_experiment(\"wiki3-kg-stage1-optimization\")\n",
    "    \n",
    "    # Enable autologging with full optimizer tracking\n",
    "    # Reference: https://dspy.ai/tutorials/optimizer_tracking/\n",
    "    mlflow.dspy.autolog(\n",
    "        log_compiles=True,\n",
    "        log_evals=True,\n",
    "        log_traces_from_compile=True\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ MLflow configured\")\n",
    "    print(f\"   Tracking URI: {MLFLOW_TRACKING_URI}\")\n",
    "    print(f\"   Experiment: wiki3-kg-stage1-optimization\")\n",
    "    MLFLOW_ENABLED = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è MLflow not available: {e}\")\n",
    "    MLFLOW_ENABLED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923827e3",
   "metadata": {},
   "source": [
    "## 3. MIPROv2 Optimization\n",
    "\n",
    "Run prompt optimization using MIPROv2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import MIPROv2\n",
    "\n",
    "# Configure optimizer\n",
    "optimizer = MIPROv2(\n",
    "    metric=statement_quality_metric,\n",
    "    auto=\"light\",  # \"light\", \"medium\", or \"heavy\"\n",
    ")\n",
    "\n",
    "NUM_FEWSHOT = config['num_fewshot']\n",
    "\n",
    "print(f\"Optimizing with {len(trainset)} training examples...\")\n",
    "print(f\"Using {NUM_FEWSHOT} few-shot demos for bootstrapping...\")\n",
    "print(f\"MIPROv2 mode: auto='light'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c076c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization\n",
    "optimized_extractor = optimizer.compile(\n",
    "    StatementExtractor(),\n",
    "    trainset=trainset,\n",
    "    max_bootstrapped_demos=NUM_FEWSHOT,\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Optimization complete!\")\n",
    "if MLFLOW_ENABLED:\n",
    "    print(f\"üìä View traces in MLflow UI: {MLFLOW_TRACKING_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c9a8ab",
   "metadata": {},
   "source": [
    "## 4. Evaluate Optimized Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b27b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on dev set\n",
    "EVAL_SIZE = min(10, len(devset))\n",
    "\n",
    "evaluator = dspy.Evaluate(\n",
    "    devset=devset[:EVAL_SIZE],\n",
    "    metric=statement_quality_metric,\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    ")\n",
    "\n",
    "optimized_result = evaluator(optimized_extractor)\n",
    "optimized_score = optimized_result.score if hasattr(optimized_result, 'score') else float(optimized_result)\n",
    "\n",
    "print(f\"\\nOptimized score: {optimized_score:.2f}\")\n",
    "if baseline_score is not None:\n",
    "    improvement = optimized_score - baseline_score\n",
    "    print(f\"Baseline score:  {baseline_score:.2f}\")\n",
    "    print(f\"Improvement:     {improvement:+.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7209a46f",
   "metadata": {},
   "source": [
    "## 5. Inspect Optimized Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f77a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimized extractor configuration:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if hasattr(optimized_extractor, 'demos'):\n",
    "    print(f\"\\nDemonstrations: {len(optimized_extractor.demos)}\")\n",
    "    for i, demo in enumerate(optimized_extractor.demos[:2], 1):\n",
    "        print(f\"  Demo {i}: {demo.section_context[:50]}...\")\n",
    "\n",
    "if hasattr(optimized_extractor, 'signature'):\n",
    "    print(f\"\\nSignature: {optimized_extractor.signature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ac950",
   "metadata": {},
   "source": [
    "## 6. Save Optimized Model\n",
    "\n",
    "Save with CID provenance for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12541c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save optimized extractor with provenance\n",
    "output_path = save_optimized_extractor(\n",
    "    extractor=optimized_extractor,\n",
    "    output_dir=training_dir,\n",
    "    config=config,\n",
    "    baseline_score=baseline_score,\n",
    "    optimized_score=optimized_score,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Saved optimized extractor to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c1603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save optimization results summary\n",
    "results = {\n",
    "    \"baseline_score\": baseline_score,\n",
    "    \"optimized_score\": optimized_score,\n",
    "    \"improvement\": optimized_score - baseline_score if baseline_score else None,\n",
    "    \"train_size\": len(trainset),\n",
    "    \"eval_size\": EVAL_SIZE,\n",
    "    \"num_fewshot\": NUM_FEWSHOT,\n",
    "    \"optimizer\": \"MIPROv2\",\n",
    "    \"auto_mode\": \"light\",\n",
    "    \"config_cid\": config.get('cid'),\n",
    "}\n",
    "\n",
    "results_path = training_dir / \"optimization_results.json\"\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Saved optimization results to: {results_path}\")\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0e2af",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook:\n",
    "1. Loaded config and datasets from `stage1_statements.ipynb`\n",
    "2. Ran MIPROv2 prompt optimization\n",
    "3. Evaluated the optimized extractor\n",
    "4. Saved the optimized model with provenance\n",
    "\n",
    "**Next steps**:\n",
    "- Review optimization traces in MLflow UI\n",
    "- Run Stage 2: Schema matching\n",
    "- Run Stage 3: RDF generation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
