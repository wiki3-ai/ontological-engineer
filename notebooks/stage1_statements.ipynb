{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6df303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Stage 1: Statement Extraction with DSPy\n",
    "# =============================================================================\n",
    "# This notebook orchestrates statement extraction training/evaluation.\n",
    "# All application logic is in ontological_engineer - this notebook coordinates.\n",
    "#\n",
    "# Outputs (with CID provenance):\n",
    "#   - data/training/chunks/*.ipynb - Chunked Wikipedia pages\n",
    "#   - data/training/statements.ipynb - Extracted statements\n",
    "#   - data/training/classifications.ipynb - Per-statement judgments\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/workspaces/wiki3-kg-project')\n",
    "\n",
    "import dspy\n",
    "import json\n",
    "from pathlib import Path\n",
    "from random import shuffle, seed as random_seed\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ontological_engineer import (\n",
    "    # LM Configuration\n",
    "    configure_lm,\n",
    "    # DSPy Modules\n",
    "    StatementExtractor,\n",
    "    StatementQualityJudge,\n",
    "    StatementClassifier,\n",
    "    StatementClassification,\n",
    "    # Data Loading (from provenance-tracked notebooks)\n",
    "    WikipediaPage,\n",
    "    WikipediaChunk,\n",
    "    fetch_top_pages,\n",
    "    fetch_page_content,\n",
    "    chunk_article,\n",
    "    load_sample_from_notebook,\n",
    "    load_chunks_from_notebook,\n",
    "    # Provenance-tracked output generation\n",
    "    generate_chunks_notebook_header,\n",
    "    append_chunk_cell,\n",
    "    generate_statements_notebook_header,\n",
    "    append_statements_cell,\n",
    "    generate_classifications_notebook_header,\n",
    "    append_classifications_cell,\n",
    "    save_notebook,\n",
    "    get_processed_chunk_cids,\n",
    ")\n",
    "from ontological_engineer.judges import statement_quality_metric\n",
    "from ontological_engineer.training.bootstrap import (\n",
    "    load_chunks_from_notebook as load_albert_chunks,\n",
    "    load_facts_from_notebook,\n",
    "    create_training_examples,\n",
    ")\n",
    "from src.cid import compute_cid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f86eb6",
   "metadata": {},
   "source": [
    "## 1. Configure Language Model\n",
    "\n",
    "Connect to LM Studio running Qwen-30B (or your preferred model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839f659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured LM: <dspy.clients.lm.LM object at 0xffff6d5dc2b0>\n"
     ]
    }
   ],
   "source": [
    "# Configure the LM (defaults to Qwen-30B via LM Studio)\n",
    "lm = configure_lm(\n",
    "    model=\"qwen/qwen3-coder-30b\",\n",
    "    api_base=\"http://host.docker.internal:1234/v1\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(f\"Configured LM: {lm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185bc4f7",
   "metadata": {},
   "source": [
    "## 2. Load Few-Shot Examples (Albert Einstein)\n",
    "\n",
    "Albert Einstein is our gold-standard example. These chunks and their extracted facts\n",
    "serve as few-shot demonstrations for the extractor and judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b715a0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 63 chunks from Albert Einstein\n",
      "Loaded 19 fact sets\n",
      "Created 19 few-shot examples\n"
     ]
    }
   ],
   "source": [
    "# Load Albert Einstein data for few-shot examples\n",
    "fewshot_dir = Path(\"/workspaces/wiki3-kg-project/data/albert_einstein/20251218_231446\")\n",
    "\n",
    "fewshot_chunks = load_chunks_from_notebook(fewshot_dir / \"chunks.ipynb\")\n",
    "fewshot_facts = load_facts_from_notebook(fewshot_dir / \"facts.ipynb\")\n",
    "\n",
    "print(f\"Loaded {len(fewshot_chunks)} chunks from Albert Einstein\")\n",
    "print(f\"Loaded {len(fewshot_facts)} fact sets\")\n",
    "\n",
    "# Create few-shot examples\n",
    "fewshot_examples = create_training_examples(fewshot_chunks, fewshot_facts)\n",
    "print(f\"Created {len(fewshot_examples)} few-shot examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5911ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample few-shot example:\n",
      "  Context: Albert Einstein > Introduction\n",
      "  Text: Albert Einstein (14 March 1879 ‚Äì 18 April 1955) was a German-born theoretical physicist best known for developing the theory of relativity. Einstein also made important contributions to quantum theory...\n",
      "  Statements: 28 items\n",
      "    - Albert Einstein was a German-born theoretical physicist.\n",
      "    - Albert Einstein developed the theory of relativity.\n",
      "    - Albert Einstein made important contributions to quantum theory.\n"
     ]
    }
   ],
   "source": [
    "# Show a few-shot example\n",
    "if fewshot_examples:\n",
    "    ex = fewshot_examples[0]\n",
    "    print(\"Sample few-shot example:\")\n",
    "    print(f\"  Context: {ex.section_context}\")\n",
    "    print(f\"  Text: {ex.chunk_text[:200]}...\")\n",
    "    print(f\"  Statements: {len(ex.statements)} items\")\n",
    "    for stmt in ex.statements[:3]:\n",
    "        print(f\"    - {stmt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb06944",
   "metadata": {},
   "source": [
    "## 3. Load Wikipedia Sample for Training\n",
    "\n",
    "Load the 100-page Wikipedia sample from the provenance-tracked notebook.\n",
    "If the notebook doesn't exist, fall back to JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9640f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 Wikipedia pages\n",
      "Sampling method: power_law\n",
      "\n",
      "First 10 pages:\n",
      "  - Zohran Mamdani (9,344,963 views)\n",
      "  - ChatGPT (3,639,485 views)\n",
      "  - James A. Garfield (3,524,531 views)\n",
      "  - 1989 Tiananmen Square protests and massacre (2,867,005 views)\n",
      "  - 2025 Bihar Legislative Assembly election (2,555,071 views)\n",
      "  - Mira Nair (2,503,516 views)\n",
      "  - Dick Cheney (2,186,840 views)\n",
      "  - 2026 FIFA World Cup (2,155,565 views)\n",
      "  - 1xBet (1,831,684 views)\n",
      "  - Survivor Series: WarGames (2025) (1,590,263 views)\n"
     ]
    }
   ],
   "source": [
    "# Load the Wikipedia sample (prefer provenance-tracked notebook)\n",
    "sample_notebook = Path(\"/workspaces/wiki3-kg-project/data/training/wikipedia_sample.ipynb\")\n",
    "sample_json = Path(\"/workspaces/wiki3-kg-project/data/training/wikipedia_sample.json\")\n",
    "\n",
    "if sample_notebook.exists():\n",
    "    # Load from provenance-tracked notebook\n",
    "    wiki_pages = load_sample_from_notebook(sample_notebook)\n",
    "    print(f\"‚úÖ Loaded {len(wiki_pages)} pages from provenance-tracked notebook\")\n",
    "    print(f\"   Source: {sample_notebook}\")\n",
    "elif sample_json.exists():\n",
    "    # Fall back to JSON format\n",
    "    with open(sample_json) as f:\n",
    "        wiki_sample = json.load(f)\n",
    "    wiki_pages = [WikipediaPage(title=p['title'], views=p['views']) for p in wiki_sample['pages']]\n",
    "    print(f\"‚ö†Ô∏è  Loaded {len(wiki_pages)} pages from JSON (no provenance)\")\n",
    "    print(f\"   Run sample_wikipedia_pages.ipynb to generate provenance-tracked version\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"No Wikipedia sample found. Run sample_wikipedia_pages.ipynb first.\")\n",
    "\n",
    "print(f\"\\nFirst 10 pages:\")\n",
    "for p in wiki_pages[:10]:\n",
    "    print(f\"  - {p.title} ({p.views:,} views)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceab17fa",
   "metadata": {},
   "source": [
    "## 4. Fetch and Chunk Wikipedia Pages (with CID Provenance)\n",
    "\n",
    "Fetch page content and chunk it. Each page's chunks are saved to a \n",
    "provenance-tracked notebook with CID signatures.\n",
    "\n",
    "**Note**: Uses `fetch_page_content` and `chunk_article` from `ontological_engineer` - \n",
    "no application logic defined in this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be01db74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 'Zohran Mamdani' -> 20 chunks\n",
      "First chunk: Zohran Kwame Mamdani (born October 18, 1991) is an American politician who is the mayor-elect of New York City. A member of the Democratic Party and the Democratic Socialists of America, he is set to ...\n"
     ]
    }
   ],
   "source": [
    "# Output directory for chunks notebooks\n",
    "chunks_dir = Path(\"/workspaces/wiki3-kg-project/data/training/chunks\")\n",
    "chunks_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Processing parameters\n",
    "MAX_PAGES = 20  # Increase for full training run\n",
    "MIN_CHUNK_LENGTH = 100  # Skip very short chunks\n",
    "\n",
    "# Test on one page first\n",
    "test_page = wiki_pages[0]\n",
    "print(f\"Testing on: {test_page.title}\")\n",
    "\n",
    "content = fetch_page_content(test_page.title)\n",
    "if content:\n",
    "    chunks = chunk_article(test_page.title, content)\n",
    "    # Filter short chunks\n",
    "    chunks = [c for c in chunks if len(c.text) >= MIN_CHUNK_LENGTH]\n",
    "    print(f\"  ‚Üí {len(chunks)} chunks (filtered by min_length={MIN_CHUNK_LENGTH})\")\n",
    "    if chunks:\n",
    "        print(f\"  First chunk preview: {chunks[0].text[:200]}...\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è Could not fetch content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886bea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching content for 20 pages...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:07<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 20 pages\n",
      "Total training chunks: 879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch and chunk all pages, saving each to a provenance-tracked notebook\n",
    "training_chunks = []\n",
    "pages_processed = 0\n",
    "\n",
    "print(f\"Fetching and chunking {min(MAX_PAGES, len(wiki_pages))} pages...\")\n",
    "print(f\"Chunks will be saved to: {chunks_dir}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for page in tqdm(wiki_pages[:MAX_PAGES], desc=\"Processing pages\"):\n",
    "    # Check if already processed\n",
    "    page_slug = page.title.lower().replace(' ', '_').replace('/', '_')\n",
    "    chunks_path = chunks_dir / f\"{page_slug}_chunks.ipynb\"\n",
    "    \n",
    "    if chunks_path.exists():\n",
    "        # Load from existing notebook (skip re-fetching)\n",
    "        existing_chunks = load_chunks_from_notebook(chunks_path)\n",
    "        for c in existing_chunks:\n",
    "            training_chunks.append(WikipediaChunk(\n",
    "                text=c['text'],\n",
    "                section_context=c['section_context'],\n",
    "                chunk_num=c['chunk_num'],\n",
    "                total_chunks=len(existing_chunks),\n",
    "                page_title=page.title,\n",
    "            ))\n",
    "        pages_processed += 1\n",
    "        continue\n",
    "    \n",
    "    # Fetch and chunk\n",
    "    content = fetch_page_content(page.title)\n",
    "    if not content:\n",
    "        continue\n",
    "    \n",
    "    chunks = chunk_article(page.title, content)\n",
    "    chunks = [c for c in chunks if len(c.text) >= MIN_CHUNK_LENGTH]\n",
    "    if not chunks:\n",
    "        continue\n",
    "    \n",
    "    # Create chunks notebook with CID provenance\n",
    "    nb = generate_chunks_notebook_header(\n",
    "        page_title=page.title,\n",
    "        source_url=f\"https://en.wikipedia.org/wiki/{page.title.replace(' ', '_')}\",\n",
    "    )\n",
    "    \n",
    "    # Compute a CID for the full page content (source provenance)\n",
    "    page_cid = compute_cid(content)\n",
    "    \n",
    "    # Add each chunk with CID signature\n",
    "    for chunk in chunks:\n",
    "        chunk_cid, _ = append_chunk_cell(nb, chunk, source_cid=page_cid)\n",
    "    \n",
    "    # Save the chunks notebook\n",
    "    save_notebook(nb, chunks_path)\n",
    "    \n",
    "    training_chunks.extend(chunks)\n",
    "    pages_processed += 1\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"‚úÖ Processed {pages_processed} pages\")\n",
    "print(f\"   Total training chunks: {len(training_chunks)}\")\n",
    "print(f\"   Chunks saved to: {chunks_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf50dd2",
   "metadata": {},
   "source": [
    "## 5. Initialize Extractor with Few-Shot Examples\n",
    "\n",
    "Create the statement extractor and provide Albert Einstein examples as demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e38b246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3 few-shot examples:\n",
      "  1. Albert Einstein > Introduction... (28 statements)\n",
      "  2. Albert Einstein > Life and career > Personal views... (28 statements)\n",
      "  3. Albert Einstein > Introduction... (27 statements)\n"
     ]
    }
   ],
   "source": [
    "# Select best few-shot examples (ones with good variety of statements)\n",
    "NUM_FEWSHOT = 3\n",
    "\n",
    "# Sort by statement count to get diverse examples\n",
    "sorted_fewshot = sorted(fewshot_examples, key=lambda x: len(x.statements), reverse=True)\n",
    "selected_fewshot = sorted_fewshot[:NUM_FEWSHOT]\n",
    "\n",
    "print(f\"Selected {len(selected_fewshot)} few-shot examples:\")\n",
    "for i, ex in enumerate(selected_fewshot, 1):\n",
    "    print(f\"  {i}. {ex.section_context[:50]}... ({len(ex.statements)} statements)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9896eb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractor initialized\n",
      "Few-shot examples available: 3\n"
     ]
    }
   ],
   "source": [
    "# Create extractor with few-shot demonstrations\n",
    "extractor = StatementExtractor()\n",
    "\n",
    "# In DSPy, we can provide demonstrations directly\n",
    "# The few-shot examples will be used by MIPROv2 for bootstrapping\n",
    "print(\"Extractor initialized\")\n",
    "print(f\"Few-shot examples available: {len(selected_fewshot)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4419625",
   "metadata": {},
   "source": [
    "## 6. Test Extraction on Training Sample\n",
    "\n",
    "Run the extractor on a few training chunks to verify it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea088a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on: Zohran Mamdani > Zohran Mamdani\n",
      "Text: Zohran Kwame Mamdani (born October 18, 1991) is an American politician who is the mayor-elect of New York City. A member of the Democratic Party and the Democratic Socialists of America, he is set to become New York's first Muslim and Asian American mayor. Mamdani has served as a member of the New Y...\n",
      "\n",
      "============================================================\n",
      "\n",
      "Extracted 22 statements:\n",
      "  1. [Zohran Kwame Mamdani](/wiki/Zohran_Kwame_Mamdani) was born on October 18, 1991.\n",
      "  2. [Zohran Kwame Mamdani](/wiki/Zohran_Kwame_Mamdani) is an American politician.\n",
      "  3. [Zohran Kwame Mamdani](/wiki/Zohran_Kwame_Mamdani) is the mayor-elect of [New York City](/wiki/New_York_City).\n",
      "  4. [Zohran Kwame Mamdani](/wiki/Zohran_Kwame_Mamdani) is a member of the [Democratic Party](/wiki/Democratic_Party).\n",
      "  5. [Zohran Kwame Mamdani](/wiki/Zohran_Kwame_Mamdani) is a member of the [Democratic Socialists of America](/wiki/Democratic_Socialists_of_America).\n",
      "  6. [Zohran Kwame Mamdani](/wiki/Zohran_Kwame_Mamdani) is set to become [New York City](/wiki/New_York_City)'s first Muslim mayor.\n",
      "  7. [Zohran Kwame Mamdani](/wiki/Zohran_Kwame_Mamdani) is set to become [New York City](/wiki/New_York_City)'s first Asian American mayor.\n",
      "  8. [Zohran Kwame Mamdani](/wiki/Zohran_Kwame_Mamdani) has served as a member of the [New York State Assembly](/wiki/New_York_State_Assembly) for the 36th district since 2021.\n",
      "  9. [Zohran Kwame Mamdani](/wiki/Zohran_Kwame_Mamdani) represents the [Queens](/wiki/Queens) neighborhood of [Astoria](/wiki/Astoria,_New_York).\n",
      "  10. [Zohran Kwame Mamdani](/wiki/Zohran_Kwame_Mamdani) was born in [Kampala](/wiki/Kampala), [Uganda](/wiki/Uganda).\n",
      "  ... and 12 more\n"
     ]
    }
   ],
   "source": [
    "# Test on a training chunk\n",
    "if training_chunks:\n",
    "    test_chunk = training_chunks[0]\n",
    "    \n",
    "    print(f\"Testing on: {test_chunk.section_context}\")\n",
    "    print(f\"Text: {test_chunk.text[:300]}...\")\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    \n",
    "    result = extractor(\n",
    "        chunk_text=test_chunk.text,\n",
    "        section_context=test_chunk.section_context,\n",
    "    )\n",
    "    \n",
    "    print(f\"Extracted {len(result.statements)} statements:\")\n",
    "    for i, stmt in enumerate(result.statements[:10], 1):\n",
    "        print(f\"  {i}. {stmt}\")\n",
    "    if len(result.statements) > 10:\n",
    "        print(f\"  ... and {len(result.statements) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a247a7a",
   "metadata": {},
   "source": [
    "## 7. Create Training Dataset\n",
    "\n",
    "Convert chunks into DSPy examples. For training, we need to generate initial extractions\n",
    "that can be scored and optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab9914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 703 examples\n",
      "Dev set: 176 examples\n"
     ]
    }
   ],
   "source": [
    "# Create training examples (without labels - we'll generate and judge them)\n",
    "# For DSPy optimization, we just need the inputs\n",
    "\n",
    "random_seed(42)  # For reproducibility\n",
    "\n",
    "# Convert WikipediaChunk objects to DSPy examples\n",
    "trainset_chunks = list(training_chunks)  # Make a copy\n",
    "shuffle(trainset_chunks)\n",
    "\n",
    "trainset = []\n",
    "for chunk in trainset_chunks:\n",
    "    ex = dspy.Example(\n",
    "        chunk_text=chunk.text,\n",
    "        section_context=chunk.section_context,\n",
    "    ).with_inputs('chunk_text', 'section_context')\n",
    "    trainset.append(ex)\n",
    "\n",
    "# Split into train/dev\n",
    "split_idx = int(len(trainset) * 0.8)\n",
    "devset = trainset[split_idx:]\n",
    "trainset = trainset[:split_idx]\n",
    "\n",
    "print(f\"Training set: {len(trainset)} examples\")\n",
    "print(f\"Dev set: {len(devset)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda75e24",
   "metadata": {},
   "source": [
    "## 8. Initialize Judge with Few-Shot Guidance\n",
    "\n",
    "The judge scores extraction quality. We use Albert Einstein examples to calibrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "792d6e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge calibration on few-shot example:\n",
      "  Completeness:      0.95\n",
      "  Atomicity:         0.85\n",
      "  Accuracy:          0.95\n",
      "  Link preservation: 1.00\n",
      "  ---\n",
      "  Weighted score:    0.94\n"
     ]
    }
   ],
   "source": [
    "# Initialize judge\n",
    "judge = StatementQualityJudge()\n",
    "\n",
    "# Test judge on a known good example (Albert Einstein few-shot)\n",
    "if selected_fewshot:\n",
    "    test_ex = selected_fewshot[0]\n",
    "    \n",
    "    evaluation = judge(\n",
    "        chunk_text=test_ex.chunk_text,\n",
    "        section_context=test_ex.section_context,\n",
    "        statements=test_ex.statements,\n",
    "    )\n",
    "    \n",
    "    print(\"Judge calibration on few-shot example:\")\n",
    "    print(f\"  Completeness:      {evaluation.completeness:.2f}\")\n",
    "    print(f\"  Atomicity:         {evaluation.atomicity:.2f}\")\n",
    "    print(f\"  Accuracy:          {evaluation.accuracy:.2f}\")\n",
    "    print(f\"  Link preservation: {evaluation.link_preservation:.2f}\")\n",
    "    print(f\"  ---\")\n",
    "    print(f\"  Weighted score:    {evaluation.weighted_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649d2fc",
   "metadata": {},
   "source": [
    "## 9. Baseline Evaluation\n",
    "\n",
    "Evaluate the unoptimized extractor on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f230a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.72 / 10 (87.2%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 244.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/20 03:52:56 INFO dspy.evaluate.evaluate: Average Metric: 8.724999999999998 / 10 (87.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Baseline quality score: 87.25\n"
     ]
    }
   ],
   "source": [
    "# Evaluate baseline on dev set\n",
    "EVAL_SIZE = min(10, len(devset))  # Limit for speed\n",
    "\n",
    "evaluator = dspy.Evaluate(\n",
    "    devset=devset[:EVAL_SIZE],\n",
    "    metric=statement_quality_metric,\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    ")\n",
    "\n",
    "baseline_extractor = StatementExtractor()\n",
    "baseline_result = evaluator(baseline_extractor)\n",
    "\n",
    "baseline_score = baseline_result.score if hasattr(baseline_result, 'score') else float(baseline_result)\n",
    "print(f\"\\nBaseline quality score: {baseline_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6e36a0",
   "metadata": {},
   "source": [
    "## 9b. MLflow Observability Setup\n",
    "\n",
    "MLflow provides tracing, evaluation, and human feedback tools for DSPy pipelines.\n",
    "\n",
    "### Quick Setup (One-time)\n",
    "\n",
    "1. **Install MLflow** (already in requirements or run cell below)\n",
    "2. **Start the MLflow server** in a terminal:\n",
    "   ```bash\n",
    "   cd /workspaces/wiki3-kg-project\n",
    "   mlflow server \\\n",
    "     --backend-store-uri sqlite:///mlflow.sqlite \\\n",
    "     --default-artifact-root ./mlflow-artifacts \\\n",
    "     --host 0.0.0.0 \\\n",
    "     --port 5000\n",
    "   ```\n",
    "3. **Open the UI** at http://localhost:5000 (or via VS Code port forwarding)\n",
    "\n",
    "### What MLflow Provides\n",
    "- **Tracing**: See every LM call, inputs, outputs, latency\n",
    "- **Evaluation**: Compare model versions side-by-side\n",
    "- **Human Feedback**: Add labels/assessments directly in the UI\n",
    "- **Experiment Tracking**: Track metrics across optimization runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87efb9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLflow configured successfully\n",
      "   Tracking URI: http://127.0.0.1:5000\n",
      "   Experiment: wiki3-kg-stage1-statements\n",
      "\n",
      "üìä Open MLflow UI: http://127.0.0.1:5000\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MLflow Setup\n",
    "# =============================================================================\n",
    "# Prerequisites:\n",
    "#   1. Install: pip install \"mlflow>=3.0\"\n",
    "#   2. Start server in terminal (or run: ./scripts/start_mlflow.sh):\n",
    "#      mlflow server --backend-store-uri sqlite:///mlflow.sqlite \\\n",
    "#                    --default-artifact-root ./mlflow-artifacts \\\n",
    "#                    --host 0.0.0.0 --port 5000\n",
    "#   3. Open UI: http://localhost:5000\n",
    "# =============================================================================\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# Configure MLflow - use localhost for local server\n",
    "# For Docker: use host.docker.internal if MLflow runs on host\n",
    "MLFLOW_TRACKING_URI = \"http://127.0.0.1:5000\"\n",
    "\n",
    "try:\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    mlflow.set_experiment(\"wiki3-kg-stage1-statements\")\n",
    "    \n",
    "    # Enable automatic DSPy tracing - captures all LM calls, modules, predictions\n",
    "    mlflow.dspy.autolog()\n",
    "    \n",
    "    print(f\"‚úÖ MLflow configured successfully\")\n",
    "    print(f\"   Tracking URI: {MLFLOW_TRACKING_URI}\")\n",
    "    print(f\"   Experiment: wiki3-kg-stage1-statements\")\n",
    "    print(f\"\\nüìä Open MLflow UI: {MLFLOW_TRACKING_URI}\")\n",
    "    MLFLOW_ENABLED = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  MLflow not available: {e}\")\n",
    "    print(f\"\\nüí° To enable MLflow, start the server:\")\n",
    "    print(f\"   mlflow server --backend-store-uri sqlite:///mlflow.sqlite --port 5000\")\n",
    "    MLFLOW_ENABLED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de34b2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Evaluation complete!\n",
      "   Average score: 0.87\n",
      "   Traces logged: 10\n",
      "\n",
      "üìä Review in MLflow UI: http://127.0.0.1:5000\n",
      "   ‚Üí Click 'Traces' tab to see all predictions\n",
      "   ‚Üí Click individual traces to review inputs/outputs\n",
      "   ‚Üí Use 'Feedback' to add human labels\n",
      "üèÉ View run baseline_evaluation at: http://127.0.0.1:5000/#/experiments/1/runs/25371954037f42588eb5cbabf53efab4\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-1d34d08e7a4c75d4dc99e04cf0e98b3b&amp;experiment_id=1&amp;trace_id=tr-7354ea6f6160745985c7504bc693da11&amp;experiment_id=1&amp;trace_id=tr-00af5b3a2812859a1337739e8d4f5d27&amp;experiment_id=1&amp;trace_id=tr-8b6870b51d61fac36cd5e85932a447b2&amp;experiment_id=1&amp;trace_id=tr-7e695d0d8a3c3b5e801ef1da45b1ed25&amp;experiment_id=1&amp;trace_id=tr-c19ad58cc35b1c8c0a4c9f7f9384ec2b&amp;experiment_id=1&amp;trace_id=tr-49c8a43f7ed70ed7b194990b6961929e&amp;experiment_id=1&amp;trace_id=tr-5c9d927d84b871bb300568d20de051a6&amp;experiment_id=1&amp;trace_id=tr-8d60593603802b708d03c91e4f8d5238&amp;experiment_id=1&amp;trace_id=tr-6232b17a250741818d1fb54074eff545&amp;experiment_id=1&amp;version=3.7.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=tr-1d34d08e7a4c75d4dc99e04cf0e98b3b), Trace(trace_id=tr-7354ea6f6160745985c7504bc693da11), Trace(trace_id=tr-00af5b3a2812859a1337739e8d4f5d27), Trace(trace_id=tr-8b6870b51d61fac36cd5e85932a447b2), Trace(trace_id=tr-7e695d0d8a3c3b5e801ef1da45b1ed25), Trace(trace_id=tr-c19ad58cc35b1c8c0a4c9f7f9384ec2b), Trace(trace_id=tr-49c8a43f7ed70ed7b194990b6961929e), Trace(trace_id=tr-5c9d927d84b871bb300568d20de051a6), Trace(trace_id=tr-8d60593603802b708d03c91e4f8d5238), Trace(trace_id=tr-6232b17a250741818d1fb54074eff545)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run evaluation with MLflow tracing (if enabled)\n",
    "# Each prediction creates a trace viewable in the MLflow UI\n",
    "\n",
    "if MLFLOW_ENABLED:\n",
    "    with mlflow.start_run(run_name=\"baseline_evaluation\"):\n",
    "        # Log parameters for reproducibility\n",
    "        mlflow.log_param(\"eval_size\", EVAL_SIZE)\n",
    "        mlflow.log_param(\"model\", \"qwen/qwen3-coder-30b\")\n",
    "        mlflow.log_param(\"num_fewshot\", NUM_FEWSHOT)\n",
    "        \n",
    "        # Run extractions on dev set - each one is traced\n",
    "        results = []\n",
    "        for i, ex in enumerate(tqdm(devset[:EVAL_SIZE], desc=\"Evaluating\")):\n",
    "            with mlflow.start_span(name=f\"example_{i}\") as span:\n",
    "                # Run extraction\n",
    "                pred = baseline_extractor(\n",
    "                    chunk_text=ex.chunk_text,\n",
    "                    section_context=ex.section_context,\n",
    "                )\n",
    "                \n",
    "                # Run judge\n",
    "                eval_result = judge(\n",
    "                    chunk_text=ex.chunk_text,\n",
    "                    section_context=ex.section_context,\n",
    "                    statements=pred.statements,\n",
    "                )\n",
    "                \n",
    "                # Log to span for MLflow UI review\n",
    "                span.set_inputs({\n",
    "                    \"chunk_text\": ex.chunk_text[:500],\n",
    "                    \"section_context\": ex.section_context,\n",
    "                })\n",
    "                span.set_outputs({\n",
    "                    \"statements\": list(pred.statements),\n",
    "                    \"completeness\": float(eval_result.completeness),\n",
    "                    \"atomicity\": float(eval_result.atomicity),\n",
    "                    \"accuracy\": float(eval_result.accuracy),\n",
    "                    \"link_preservation\": float(eval_result.link_preservation),\n",
    "                    \"weighted_score\": float(eval_result.weighted_score),\n",
    "                    \"reasoning\": eval_result.reasoning,\n",
    "                })\n",
    "                \n",
    "                results.append({\n",
    "                    \"index\": i,\n",
    "                    \"score\": float(eval_result.weighted_score),\n",
    "                })\n",
    "        \n",
    "        # Log aggregate metrics\n",
    "        avg_score = sum(r[\"score\"] for r in results) / len(results)\n",
    "        mlflow.log_metric(\"avg_quality_score\", avg_score)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Evaluation complete!\")\n",
    "        print(f\"   Average score: {avg_score:.2f}\")\n",
    "        print(f\"   Traces logged: {len(results)}\")\n",
    "        print(f\"\\nüìä Review in MLflow UI: {MLFLOW_TRACKING_URI}\")\n",
    "        print(f\"   ‚Üí Click 'Traces' tab to see all predictions\")\n",
    "        print(f\"   ‚Üí Click individual traces to review inputs/outputs\")\n",
    "        print(f\"   ‚Üí Use 'Feedback' to add human labels\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping MLflow evaluation (server not running)\")\n",
    "    print(\"   Run baseline evaluation with dspy.Evaluate instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "794a21f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent LM calls (use MLflow UI for full traces):\n",
      "============================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-12-20T03:52:59.613246]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `chunk_text` (str): Wikipedia article chunk with markdown links preserved\n",
      "2. `section_context` (str): Breadcrumb showing location: Article > Section > Subsection\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `statements` (list[str]): List of atomic statements, each preserving [Entity](/wiki/...) links\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## chunk_text ## ]]\n",
      "{chunk_text}\n",
      "\n",
      "[[ ## section_context ## ]]\n",
      "{section_context}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## statements ## ]]\n",
      "{statements}        # note: the value you produce must adhere to the JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Extract atomic, verifiable statements from Wikipedia text.\n",
      "        \n",
      "        Each statement must:\n",
      "        - Be self-contained (understandable without the original text)\n",
      "        - Preserve markdown links: [Entity Name](/wiki/Entity_Name)\n",
      "        - Contain exactly one verifiable claim\n",
      "        - Not editorialize or interpret beyond what's stated\n",
      "        \n",
      "        Example input chunk:\n",
      "            \"Albert Einstein was born in Ulm, in the Kingdom of W√ºrttemberg \n",
      "            in the German Empire, on 14 March 1879.\"\n",
      "        \n",
      "        Example output statements:\n",
      "            - \"[Albert Einstein](/wiki/Albert_Einstein) was born in [Ulm](/wiki/Ulm).\"\n",
      "            - \"[Albert Einstein](/wiki/Albert_Einstein) was born on 14 March 1879.\"\n",
      "            - \"[Ulm](/wiki/Ulm) was in the [Kingdom of W√ºrttemberg](/wiki/Kingdom_of_W√ºrttemberg).\"\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## chunk_text ## ]]\n",
      "Kirk was the author of several books. Along with Brent Hamachek, he co-wrote the 2016 book Time for a Turning Point: Setting a Course Toward Free Markets and Limited Government for Future Generations, which was published by Post Hill Press, a subsidiary of Simon & Schuster. Under the same publisher, Kirk wrote the 2018 book Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters. Donald Trump Jr. wrote the foreword for the book. In a review for The Weekly Standard, Adam Rubenstein described the book as a \"hot mess\", \"nothing more than a marketing pitch for TPUSA\", and said the \"thin\" book was \"stuffed with reprintings of his tweets and quotes from others\".\n",
      "In 2020, Kirk wrote The MAGA Doctrine: The Only Ideas That Will Win the Future, which was published by Harper Collins. In its review for The New York Times, Gabriel Debenedetti wrote that \"Kirk's musing about whether 'The Art of The Deal' might one day be considered a 'religious tract' comes just nine chapters after the book highlights the importance of 'a healthy dose of skepticism about authority figures and experts who think they knew best.' And that's just pages after its dedication to Donald Trump, which is five chapters before Kirk wonders whether Trump might 'be remembered as the president who brought about world peace.'\" In Open Letters Review, Steve Donoghue said of the book that \"On every page, Kirk writes something that's either trivially, casually wrong ..\n",
      "\n",
      "[[ ## section_context ## ]]\n",
      "Charlie Kirk > Books\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## statements ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The chunk text contains several verifiable claims about Charlie Kirk's books, their authors, publishers, reviews, and content. Each sentence or group of sentences forms a distinct atomic statement that can stand alone and be verified independently. The statements must preserve markdown links if present (though none are in this case), and each must contain exactly one verifiable claim.\n",
      "\n",
      "The key claims to extract include:\n",
      "1. Kirk authored several books.\n",
      "2. He co-wrote a 2016 book with Brent Hamachek titled \"Time for a Turning Point...\" published by Post Hill Press.\n",
      "3. He wrote another 2018 book titled \"Campus Battlefield...\" under the same publisher.\n",
      "4. Donald Trump Jr. wrote the foreword for \"Campus Battlefield...\".\n",
      "5. Adam Rubenstein reviewed \"Campus Battlefield...\" and called it a \"hot mess\" and criticized its content.\n",
      "6. In 2020, Kirk wrote \"The MAGA Doctrine...\" published by Harper Collins.\n",
      "7. Gabriel Debenedetti reviewed \"The MAGA Doctrine...\" for The New York Times and criticized its inconsistencies.\n",
      "8. Steve Donoghue reviewed \"The MAGA Doctrine...\" for Open Letters Review and criticized its accuracy.\n",
      "\n",
      "[[ ## statements ## ]]\n",
      "[\n",
      "    \"[Charlie Kirk](/wiki/Charlie_Kirk) was the author of several books.\",\n",
      "    \"[Charlie Kirk](/wiki/Charlie_Kirk) co-wrote the 2016 book [Time for a Turning Point: Setting a Course Toward Free Markets and Limited Government for Future Generations](/wiki/Time_for_a_Turning_Point) with [Brent Hamachek](/wiki/Brent_Hamachek).\",\n",
      "    \"The 2016 book [Time for a Turning Point: Setting a Course Toward Free Markets and Limited Government for Future Generations](/wiki/Time_for_a_Turning_Point) was published by [Post Hill Press](/wiki/Post_Hill_Press).\",\n",
      "    \"[Post Hill Press](/wiki/Post_Hill_Press) is a subsidiary of [Simon & Schuster](/wiki/Simon_%26_Schuster).\",\n",
      "    \"[Charlie Kirk](/wiki/Charlie_Kirk) wrote the 2018 book [Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters](/wiki/Campus_Battlefield).\",\n",
      "    \"[Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters](/wiki/Campus_Battlefield) was published by [Post Hill Press](/wiki/Post_Hill_Press).\",\n",
      "    \"[Donald Trump Jr.](/wiki/Donald_Trump_Jr.) wrote the foreword for [Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters](/wiki/Campus_Battlefield).\",\n",
      "    \"In a review for [The Weekly Standard](/wiki/The_Weekly_Standard), [Adam Rubenstein](/wiki/Adam_Rubenstein) described [Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters](/wiki/Campus_Battlefield) as a 'hot mess'.\",\n",
      "    \"In a review for [The Weekly Standard](/wiki/The_Weekly_Standard), [Adam Rubenstein](/wiki/Adam_Rubenstein) said [Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters](/wiki/Campus_Battlefield) was 'nothing more than a marketing pitch for TPUSA'.\",\n",
      "    \"In a review for [The Weekly Standard](/wiki/The_Weekly_Standard), [Adam Rubenstein](/wiki/Adam_Rubenstein) said the 'thin' book [Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters](/wiki/Campus_Battlefield) was 'stuffed with reprintings of his tweets and quotes from others'.\",\n",
      "    \"[Charlie Kirk](/wiki/Charlie_Kirk) wrote the 2020 book [The MAGA Doctrine: The Only Ideas That Will Win the Future](/wiki/The_MAGA_Doctrine).\",\n",
      "    \"[The MAGA Doctrine: The Only Ideas That Will Win the Future](/wiki/The_MAGA_Doctrine) was published by [Harper Collins](/wiki/Harper_Collins).\",\n",
      "    \"In its review for [The New York Times](/wiki/The_New_York_Times), [Gabriel Debenedetti](/wiki/Gabriel_Debenedetti) wrote that [Charlie Kirk](/wiki/Charlie_Kirk)'s musing about whether '[The Art of The Deal](/wiki/The_Art_of_the_Deal)' might one day be considered a 'religious tract' comes just nine chapters after the book highlights the importance of 'a healthy dose of skepticism about authority figures and experts who think they knew best'.\",\n",
      "    \"In its review for [The New York Times](/wiki/The_New_York_Times), [Gabriel Debenedetti](/wiki/Gabriel_Debenedetti) wrote that the book [The MAGA Doctrine: The Only Ideas That Will Win the Future](/wiki/The_MAGA_Doctrine) highlights the importance of 'a healthy dose of skepticism about authority figures and experts who think they knew best.'\",\n",
      "    \"In its review for [The New York Times](/wiki/The_New_York_Times), [Gabriel Debenedetti](/wiki/Gabriel_Debenedetti) wrote that the book [The MAGA Doctrine: The Only Ideas That Will Win the Future](/wiki/The_MAGA_Doctrine) dedicates itself to [Donald Trump](/wiki/Donald_Trump).\",\n",
      "    \"In its review for [The New York Times](/wiki/The_New_York_Times), [Gabriel Debenedetti](/wiki/Gabriel_Debenedetti) wrote that the book [The MAGA Doctrine: The Only Ideas That Will Win the Future](/wiki/The_MAGA_Doctrine) highlights that [Donald Trump](/wiki/Donald_Trump) might 'be remembered as the president who brought about world peace.'\",\n",
      "    \"In [Open Letters Review](/wiki/Open_Letters_Review), [Steve Donoghue](/wiki/Steve_Donoghue) said of the book [The MAGA Doctrine: The Only Ideas That Will Win the Future](/wiki/The_MAGA_Doctrine) that 'On every page, [Charlie Kirk](/wiki/Charlie_Kirk) writes something that's either trivially, casually wrong.'\"\n",
      "]\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-12-20T03:52:59.666542]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `chunk_text` (str): Original Wikipedia chunk\n",
      "2. `section_context` (str): Section breadcrumb for context\n",
      "3. `statements` (list[str]): Extracted statements to evaluate\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): Brief explanation of the scores given\n",
      "2. `completeness` (float): Score 0-1: Are all key facts from the chunk captured?\n",
      "3. `atomicity` (float): Score 0-1: Is each statement truly atomic (one claim)?\n",
      "4. `accuracy` (float): Score 0-1: Do statements faithfully represent the source?\n",
      "5. `link_preservation` (float): Score 0-1: Are [Entity](/wiki/...) links preserved correctly?\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## chunk_text ## ]]\n",
      "{chunk_text}\n",
      "\n",
      "[[ ## section_context ## ]]\n",
      "{section_context}\n",
      "\n",
      "[[ ## statements ## ]]\n",
      "{statements}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## completeness ## ]]\n",
      "{completeness}        # note: the value you produce must be a single float value\n",
      "\n",
      "[[ ## atomicity ## ]]\n",
      "{atomicity}        # note: the value you produce must be a single float value\n",
      "\n",
      "[[ ## accuracy ## ]]\n",
      "{accuracy}        # note: the value you produce must be a single float value\n",
      "\n",
      "[[ ## link_preservation ## ]]\n",
      "{link_preservation}        # note: the value you produce must be a single float value\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Judge the quality of extracted statements from a Wikipedia chunk.\n",
      "        \n",
      "        Evaluate on four dimensions:\n",
      "        1. Completeness: Are all key facts from the chunk captured?\n",
      "        2. Atomicity: Is each statement truly atomic (one verifiable claim)?\n",
      "        3. Accuracy: Do statements faithfully represent the source without adding info?\n",
      "        4. Link preservation: Are [Entity](/wiki/...) links preserved correctly?\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## chunk_text ## ]]\n",
      "Kirk was the author of several books. Along with Brent Hamachek, he co-wrote the 2016 book Time for a Turning Point: Setting a Course Toward Free Markets and Limited Government for Future Generations, which was published by Post Hill Press, a subsidiary of Simon & Schuster. Under the same publisher, Kirk wrote the 2018 book Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters. Donald Trump Jr. wrote the foreword for the book. In a review for The Weekly Standard, Adam Rubenstein described the book as a \"hot mess\", \"nothing more than a marketing pitch for TPUSA\", and said the \"thin\" book was \"stuffed with reprintings of his tweets and quotes from others\".\n",
      "In 2020, Kirk wrote The MAGA Doctrine: The Only Ideas That Will Win the Future, which was published by Harper Collins. In its review for The New York Times, Gabriel Debenedetti wrote that \"Kirk's musing about whether 'The Art of The Deal' might one day be considered a 'religious tract' comes just nine chapters after the book highlights the importance of 'a healthy dose of skepticism about authority figures and experts who think they knew best.' And that's just pages after its dedication to Donald Trump, which is five chapters before Kirk wonders whether Trump might 'be remembered as the president who brought about world peace.'\" In Open Letters Review, Steve Donoghue said of the book that \"On every page, Kirk writes something that's either trivially, casually wrong ..\n",
      "\n",
      "[[ ## section_context ## ]]\n",
      "Charlie Kirk > Books\n",
      "\n",
      "[[ ## statements ## ]]\n",
      "[\"[Charlie Kirk](/wiki/Charlie_Kirk) was the author of several books.\", \"[Charlie Kirk](/wiki/Charlie_Kirk) co-wrote the 2016 book [Time for a Turning Point: Setting a Course Toward Free Markets and Limited Government for Future Generations](/wiki/Time_for_a_Turning_Point) with [Brent Hamachek](/wiki/Brent_Hamachek).\", \"The 2016 book [Time for a Turning Point: Setting a Course Toward Free Markets and Limited Government for Future Generations](/wiki/Time_for_a_Turning_Point) was published by [Post Hill Press](/wiki/Post_Hill_Press).\", \"[Post Hill Press](/wiki/Post_Hill_Press) is a subsidiary of [Simon & Schuster](/wiki/Simon_%26_Schuster).\", \"[Charlie Kirk](/wiki/Charlie_Kirk) wrote the 2018 book [Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters](/wiki/Campus_Battlefield).\", \"[Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters](/wiki/Campus_Battlefield) was published by [Post Hill Press](/wiki/Post_Hill_Press).\", \"[Donald Trump Jr.](/wiki/Donald_Trump_Jr.) wrote the foreword for [Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters](/wiki/Campus_Battlefield).\", \"In a review for [The Weekly Standard](/wiki/The_Weekly_Standard), [Adam Rubenstein](/wiki/Adam_Rubenstein) described [Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters](/wiki/Campus_Battlefield) as a 'hot mess'.\", \"In a review for [The Weekly Standard](/wiki/The_Weekly_Standard), [Adam Rubenstein](/wiki/Adam_Rubenstein) said [Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters](/wiki/Campus_Battlefield) was 'nothing more than a marketing pitch for TPUSA'.\", \"In a review for [The Weekly Standard](/wiki/The_Weekly_Standard), [Adam Rubenstein](/wiki/Adam_Rubenstein) said the 'thin' book [Campus Battlefield: How Conservatives Can WIN the Battle on Campus and Why It Matters](/wiki/Campus_Battlefield) was 'stuffed with reprintings of his tweets and quotes from others'.\", \"[Charlie Kirk](/wiki/Charlie_Kirk) wrote the 2020 book [The MAGA Doctrine: The Only Ideas That Will Win the Future](/wiki/The_MAGA_Doctrine).\", \"[The MAGA Doctrine: The Only Ideas That Will Win the Future](/wiki/The_MAGA_Doctrine) was published by [Harper Collins](/wiki/Harper_Collins).\", \"In its review for [The New York Times](/wiki/The_New_York_Times), [Gabriel Debenedetti](/wiki/Gabriel_Debenedetti) wrote that [Charlie Kirk](/wiki/Charlie_Kirk)'s musing about whether '[The Art of The Deal](/wiki/The_Art_of_the_Deal)' might one day be considered a 'religious tract' comes just nine chapters after the book highlights the importance of 'a healthy dose of skepticism about authority figures and experts who think they knew best'.\", \"In its review for [The New York Times](/wiki/The_New_York_Times), [Gabriel Debenedetti](/wiki/Gabriel_Debenedetti) wrote that the book [The MAGA Doctrine: The Only Ideas That Will Win the Future](/wiki/The_MAGA_Doctrine) highlights the importance of 'a healthy dose of skepticism about authority figures and experts who think they knew best.'\", \"In its review for [The New York Times](/wiki/The_New_York_Times), [Gabriel Debenedetti](/wiki/Gabriel_Debenedetti) wrote that the book [The MAGA Doctrine: The Only Ideas That Will Win the Future](/wiki/The_MAGA_Doctrine) dedicates itself to [Donald Trump](/wiki/Donald_Trump).\", \"In its review for [The New York Times](/wiki/The_New_York_Times), [Gabriel Debenedetti](/wiki/Gabriel_Debenedetti) wrote that the book [The MAGA Doctrine: The Only Ideas That Will Win the Future](/wiki/The_MAGA_Doctrine) highlights that [Donald Trump](/wiki/Donald_Trump) might 'be remembered as the president who brought about world peace.'\", \"In [Open Letters Review](/wiki/Open_Letters_Review), [Steve Donoghue](/wiki/Steve_Donoghue) said of the book [The MAGA Doctrine: The Only Ideas That Will Win the Future](/wiki/The_MAGA_Doctrine) that 'On every page, [Charlie Kirk](/wiki/Charlie_Kirk) writes something that's either trivially, casually wrong.'\"]\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## completeness ## ]]` (must be formatted as a valid Python float), then `[[ ## atomicity ## ]]` (must be formatted as a valid Python float), then `[[ ## accuracy ## ]]` (must be formatted as a valid Python float), then `[[ ## link_preservation ## ]]` (must be formatted as a valid Python float), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The extracted statements capture most of the key facts from the chunk, including the books authored by Charlie Kirk, their publication details, publishers, forewords, and reviews. However, some nuances are lost in translation, particularly in the review excerpts where the full context of the criticism is not fully represented. The statements are generally atomic, each containing a single verifiable claim. Links are preserved correctly for all entities mentioned. Accuracy is high, though some statements slightly paraphrase the original text, which may affect precision.\n",
      "\n",
      "[[ ## completeness ## ]]\n",
      "0.9\n",
      "\n",
      "[[ ## atomicity ## ]]\n",
      "0.95\n",
      "\n",
      "[[ ## accuracy ## ]]\n",
      "0.9\n",
      "\n",
      "[[ ## link_preservation ## ]]\n",
      "1.0\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Use dspy.inspect_history() for quick debugging\n",
    "# This shows recent LM calls without needing MLflow server\n",
    "\n",
    "print(\"Recent LM calls (use MLflow UI for full traces):\")\n",
    "print(\"=\" * 60)\n",
    "dspy.inspect_history(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d708ef8",
   "metadata": {},
   "source": [
    "### MLflow Evaluation with Human Feedback\n",
    "\n",
    "Use MLflow's evaluation API to systematically review predictions and collect human labels.\n",
    "The MLflow UI provides a proper interface for reviewing and annotating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5de353ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created evaluation dataset with 10 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>section_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>In an interview with Wired magazine during the...</td>\n",
       "      <td>Charlie Kirk &gt; Republican and pro-Trump activism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>. He has described his upbringing as \"privileg...</td>\n",
       "      <td>Zohran Mamdani &gt; Early life and education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Wikipedia has spawned several sister projects,...</td>\n",
       "      <td>Wikipedia &gt; Sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>. Throughout the demonstrations, broadcasts by...</td>\n",
       "      <td>1989 Tiananmen Square protests and massacre &gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The visual effects for Wicked were made by Ind...</td>\n",
       "      <td>Wicked (2024 film) &gt; Post-production and visua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         chunk_text  \\\n",
       "0      0  In an interview with Wired magazine during the...   \n",
       "1      1  . He has described his upbringing as \"privileg...   \n",
       "2      2  Wikipedia has spawned several sister projects,...   \n",
       "3      3  . Throughout the demonstrations, broadcasts by...   \n",
       "4      4  The visual effects for Wicked were made by Ind...   \n",
       "\n",
       "                                     section_context  \n",
       "0   Charlie Kirk > Republican and pro-Trump activism  \n",
       "1          Zohran Mamdani > Early life and education  \n",
       "2                        Wikipedia > Sister projects  \n",
       "3  1989 Tiananmen Square protests and massacre > ...  \n",
       "4  Wicked (2024 film) > Post-production and visua...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create evaluation dataset for MLflow\n",
    "import pandas as pd\n",
    "\n",
    "eval_data = []\n",
    "for i, ex in enumerate(devset[:EVAL_SIZE]):\n",
    "    eval_data.append({\n",
    "        \"index\": i,\n",
    "        \"chunk_text\": ex.chunk_text,\n",
    "        \"section_context\": ex.section_context,\n",
    "    })\n",
    "\n",
    "eval_df = pd.DataFrame(eval_data)\n",
    "print(f\"Created evaluation dataset with {len(eval_df)} examples\")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b02ec641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying statements for 10 chunks...\n",
      "======================================================================\n",
      "\n",
      "[1/10] Charlie Kirk > Republican and pro-Trump activism...\n",
      "   ‚Üí 10/10 GOOD (100%)\n",
      "\n",
      "[2/10] Zohran Mamdani > Early life and education...\n",
      "   ‚Üí 23/23 GOOD (100%)\n",
      "\n",
      "[3/10] Wikipedia > Sister projects...\n",
      "   ‚Üí 10/10 GOOD (100%)\n",
      "\n",
      "[4/10] 1989 Tiananmen Square protests and massacre > 1986...\n",
      "   ‚Üí 6/6 GOOD (100%)\n",
      "\n",
      "[5/10] Wicked (2024 film) > Post-production and visual ef...\n",
      "   ‚Üí 16/16 GOOD (100%)\n",
      "\n",
      "[6/10] Wikipedia > Community...\n",
      "   ‚Üí 8/10 GOOD (80%)\n",
      "\n",
      "[7/10] Wikipedia > Sources...\n",
      "   ‚Üí 0/0 GOOD (0%)\n",
      "\n",
      "[8/10] Wikipedia > Explicit content...\n",
      "   ‚Üí 15/15 GOOD (100%)\n",
      "\n",
      "[9/10] Marjorie Taylor Greene > Runoff election...\n",
      "   ‚Üí 6/6 GOOD (100%)\n",
      "\n",
      "[10/10] Charlie Kirk > Books...\n",
      "   ‚Üí 17/17 GOOD (100%)\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Average score: 88.0%\n",
      "Total GOOD: 111, Total BAD: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-da330aa1541cdfcdda0d4a5f148f8b74&amp;experiment_id=1&amp;trace_id=tr-118405ad9e11d2cd0930aef68a80068d&amp;experiment_id=1&amp;trace_id=tr-df615a5cb4323070a23d4c2fc2a79689&amp;experiment_id=1&amp;trace_id=tr-25440fe06e417d475ff595ea5bc440f1&amp;experiment_id=1&amp;trace_id=tr-3da70577aee1e86b9ea556aa61ee6c5b&amp;experiment_id=1&amp;trace_id=tr-e6b5a92c771ad655cdfc6ee0e61ede90&amp;experiment_id=1&amp;trace_id=tr-40066ff2b0b862ef6c9f82b9f6478986&amp;experiment_id=1&amp;trace_id=tr-fe2110d04bbe4aff9326dffd5be4bf51&amp;experiment_id=1&amp;trace_id=tr-0c8e29e3f93e08d5bea29dfec73f6e1b&amp;experiment_id=1&amp;trace_id=tr-a2f963a33810ae665a31b4cccd4b69a9&amp;experiment_id=1&amp;version=3.7.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=tr-da330aa1541cdfcdda0d4a5f148f8b74), Trace(trace_id=tr-118405ad9e11d2cd0930aef68a80068d), Trace(trace_id=tr-df615a5cb4323070a23d4c2fc2a79689), Trace(trace_id=tr-25440fe06e417d475ff595ea5bc440f1), Trace(trace_id=tr-3da70577aee1e86b9ea556aa61ee6c5b), Trace(trace_id=tr-e6b5a92c771ad655cdfc6ee0e61ede90), Trace(trace_id=tr-40066ff2b0b862ef6c9f82b9f6478986), Trace(trace_id=tr-fe2110d04bbe4aff9326dffd5be4bf51), Trace(trace_id=tr-0c8e29e3f93e08d5bea29dfec73f6e1b), Trace(trace_id=tr-a2f963a33810ae665a31b4cccd4b69a9)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Per-Statement Classification for ALL Evaluation Examples\n",
    "# ============================================================================\n",
    "# Uses StatementClassifier to get GOOD/BAD verdicts per statement\n",
    "\n",
    "from ontological_engineer import StatementClassifier, StatementClassification\n",
    "\n",
    "classifier = StatementClassifier()\n",
    "\n",
    "# Store all results for summary\n",
    "all_classification_results = []\n",
    "\n",
    "print(f\"Classifying statements for {EVAL_SIZE} chunks...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for idx, ex in enumerate(devset[:EVAL_SIZE]):\n",
    "    print(f\"\\n[{idx+1}/{EVAL_SIZE}] {ex.section_context[:50]}...\")\n",
    "    \n",
    "    # Extract statements\n",
    "    pred = baseline_extractor(\n",
    "        chunk_text=ex.chunk_text,\n",
    "        section_context=ex.section_context,\n",
    "    )\n",
    "    \n",
    "    # Classify each statement\n",
    "    result = classifier(\n",
    "        chunk_text=ex.chunk_text,\n",
    "        section_context=ex.section_context,\n",
    "        statements=list(pred.statements),\n",
    "    )\n",
    "    \n",
    "    # Store result\n",
    "    all_classification_results.append({\n",
    "        \"idx\": idx,\n",
    "        \"section\": ex.section_context,\n",
    "        \"chunk_text\": ex.chunk_text,\n",
    "        \"statements\": list(pred.statements),\n",
    "        \"score\": result.score,\n",
    "        \"classifications\": result.classifications,\n",
    "        \"missing_facts\": result.missing_facts,\n",
    "    })\n",
    "    \n",
    "    # Show quick summary\n",
    "    good = sum(1 for c in result.classifications if c.is_good)\n",
    "    total = len(result.classifications)\n",
    "    print(f\"   ‚Üí {good}/{total} GOOD ({result.score:.0%})\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "avg_score = sum(r[\"score\"] for r in all_classification_results) / len(all_classification_results)\n",
    "total_good = sum(sum(1 for c in r[\"classifications\"] if c.is_good) for r in all_classification_results)\n",
    "total_bad = sum(sum(1 for c in r[\"classifications\"] if not c.is_good) for r in all_classification_results)\n",
    "print(f\"Average score: {avg_score:.1%}\")\n",
    "print(f\"Total GOOD: {total_good}, Total BAD: {total_bad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be8c9996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StatementClassification(index=0, statement='[Charlie Kirk](/wiki/Charlie_Kirk) said in an interview with [Wired](/wiki/Wired_(magazine)) magazine during the [2016 Republican National Convention](/wiki/2016_Republican_National_Convention) that while he \"was not the world\\'s biggest [Donald Trump](/wiki/Donald_Trump) fan\", he would vote for him.', classification='GOOD', reason='atomic, accurate, links preserved'),\n",
       " StatementClassification(index=1, statement=\"[Charlie Kirk](/wiki/Charlie_Kirk) said that [Trump's](/wiki/Donald_Trump) candidacy made [Turning Point](/wiki/Turning_Point_(organization))'s mission more difficult.\", classification='GOOD', reason='atomic, accurate, links preserved'),\n",
       " StatementClassification(index=2, statement='[Charlie Kirk](/wiki/Charlie_Kirk) flipped to supporting [Trump](/wiki/Donald_Trump) at the convention.', classification='GOOD', reason='atomic, accurate, links preserved'),\n",
       " StatementClassification(index=3, statement='[Charlie Kirk](/wiki/Charlie_Kirk) spent the remainder of the [2016 campaign](/wiki/2016_United_States_presidential_election) assisting with travel and media arrangements for [Donald Trump Jr.](/wiki/Donald_Trump_Jr.).', classification='GOOD', reason='atomic, accurate, links preserved'),\n",
       " StatementClassification(index=4, statement='[Charlie Kirk](/wiki/Charlie_Kirk) participated in a [Fox News](/wiki/Fox_News)_event in October 2016 along with [Donald Trump Jr.](/wiki/Donald_Trump_Jr.), [Eric Trump](/wiki/Eric_Trump), and [Lara Trump](/wiki/Lara_Trump).', classification='GOOD', reason='atomic, accurate, links preserved'),\n",
       " StatementClassification(index=5, statement='[Charlie Kirk](/wiki/Charlie_Kirk) became chairman of [Students for Trump](/wiki/Students_for_Trump) in July 2019.', classification='GOOD', reason='atomic, accurate, links preserved'),\n",
       " StatementClassification(index=6, statement='[Students for Trump](/wiki/Students_for_Trump) had been acquired by [Turning Point Action](/wiki/Turning_Point_Action).', classification='GOOD', reason='atomic, accurate, links preserved'),\n",
       " StatementClassification(index=7, statement=\"The unsuccessful effort of [Kirk's](/wiki/Charlie_Kirk) youth mobilization campaign led [TPUSA](/wiki/Turning_Point_United_States_America) and the [Trump campaign](/wiki/Donald_Trump_2016_presidential_campaign) to blame each other for an overall decline in [Trump's](/wiki/Donald_Trump) youth support.\", classification='GOOD', reason='atomic, accurate, links preserved'),\n",
       " StatementClassification(index=8, statement='[Matthew Rosenberg](/wiki/Matthew_Rosenberg) and [Katie Rogers](/wiki/Katie_Rogers) wrote in [The New York Times](/wiki/The_New_York_Times) in April 2020 that [Charlie Kirk](/wiki/Charlie_Kirk) exemplifies \"walking the line between mainstream conservative opinion and outright disinformation\".', classification='GOOD', reason='atomic, accurate, links preserved'),\n",
       " StatementClassification(index=9, statement=\"[Charlie Kirk](/wiki/Charlie_Kirk) both amplifies the [president's](/wiki/Donald_Trump)'s message and helps shape it, according to [Matthew Rosenberg](/wiki/Matthew_Rosenberg) and [Katie Rogers](/wiki/Katie_Rogers).\", classification='GOOD', reason='atomic, accurate, links preserved')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_result.classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f56db83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETAILED PER-CHUNK RESULTS\n",
      "======================================================================\n",
      "\n",
      "üìÑ Chunk 0: Charlie Kirk > Republican and pro-Trump activism...\n",
      "   Score: 100% (10/10 GOOD)\n",
      "\n",
      "üìÑ Chunk 1: Zohran Mamdani > Early life and education...\n",
      "   Score: 100% (23/23 GOOD)\n",
      "\n",
      "üìÑ Chunk 2: Wikipedia > Sister projects...\n",
      "   Score: 100% (10/10 GOOD)\n",
      "\n",
      "üìÑ Chunk 3: 1989 Tiananmen Square protests and massacre > 1986 student d...\n",
      "   Score: 100% (6/6 GOOD)\n",
      "\n",
      "üìÑ Chunk 4: Wicked (2024 film) > Post-production and visual effects...\n",
      "   Score: 100% (16/16 GOOD)\n",
      "\n",
      "üìÑ Chunk 5: Wikipedia > Community...\n",
      "   Score: 80% (8/10 GOOD)\n",
      "   ‚ùå BAD statements:\n",
      "      [3] Wikipedia's preference for cohesiveness has been referred to as \"anti-elitism\"....\n",
      "          Reason: incomplete information, omits key context about the compromise and disregard of credentials that defines \"anti-elitism\"\n",
      "      [7] [Wikipedia](/wiki/Wikipedia) is therefore \"much like any traditional organizatio...\n",
      "          Reason: misrepresents Jimmy Wales' quote, editorializing rather than faithful to source\n",
      "\n",
      "üìÑ Chunk 6: Wikipedia > Sources...\n",
      "   Score: 0% (0/0 GOOD)\n",
      "\n",
      "üìÑ Chunk 7: Wikipedia > Explicit content...\n",
      "   Score: 100% (15/15 GOOD)\n",
      "\n",
      "üìÑ Chunk 8: Marjorie Taylor Greene > Runoff election...\n",
      "   Score: 100% (6/6 GOOD)\n",
      "\n",
      "üìÑ Chunk 9: Charlie Kirk > Books...\n",
      "   Score: 100% (17/17 GOOD)\n"
     ]
    }
   ],
   "source": [
    "# Display detailed results for each chunk\n",
    "print(\"DETAILED PER-CHUNK RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for r in all_classification_results:\n",
    "    good = sum(1 for c in r[\"classifications\"] if c.is_good)\n",
    "    bad = sum(1 for c in r[\"classifications\"] if not c.is_good)\n",
    "    total = len(r[\"classifications\"])\n",
    "    \n",
    "    print(f\"\\nüìÑ Chunk {r['idx']}: {r['section'][:60]}...\")\n",
    "    print(f\"   Score: {r['score']:.0%} ({good}/{total} GOOD)\")\n",
    "    \n",
    "    # Show BAD statements (these need attention)\n",
    "    bad_stmts = [c for c in r[\"classifications\"] if not c.is_good]\n",
    "    if bad_stmts:\n",
    "        print(f\"   ‚ùå BAD statements:\")\n",
    "        for c in bad_stmts:\n",
    "            print(f\"      [{c.index}] {c.statement[:80]}...\")\n",
    "            print(f\"          Reason: {c.reason}\")\n",
    "    \n",
    "    if r[\"missing_facts\"] and r[\"missing_facts\"].lower() != \"none\":\n",
    "        print(f\"   üìù Missing: {r['missing_facts'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930c283f",
   "metadata": {},
   "source": [
    "### Export Annotations from MLflow\n",
    "\n",
    "After reviewing and labeling in the MLflow UI, export your annotations for judge improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e23dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest run: d01f36bee590481593cfe6511fc13f11\n",
      "Metrics: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24578/2900277544.py:22: FutureWarning: Parameter 'experiment_ids' is deprecated. Please use 'locations' instead.\n",
      "  traces = client.search_traces(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 traces\n"
     ]
    }
   ],
   "source": [
    "# Load annotations from MLflow (after you've labeled them in the UI)\n",
    "# MLflow stores feedback as assessments on traces\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "\n",
    "# Get the latest evaluation run\n",
    "experiment = client.get_experiment_by_name(\"wiki3-kg-stage1-statements\")\n",
    "if experiment:\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        order_by=[\"start_time DESC\"],\n",
    "        max_results=1,\n",
    "    )\n",
    "    \n",
    "    if runs:\n",
    "        latest_run = runs[0]\n",
    "        print(f\"Latest run: {latest_run.info.run_id}\")\n",
    "        print(f\"Metrics: {latest_run.data.metrics}\")\n",
    "        \n",
    "        # Get traces with assessments (human feedback)\n",
    "        try:\n",
    "            traces = client.search_traces(\n",
    "                experiment_ids=[experiment.experiment_id],\n",
    "                max_results=100,\n",
    "            )\n",
    "            print(f\"Found {len(traces)} traces\")\n",
    "        except Exception as e:\n",
    "            print(f\"Trace search error: {e}\")\n",
    "else:\n",
    "    print(\"No experiment found. Run evaluation first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c52239b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation dataset to /workspaces/wiki3-kg-project/data/training/eval_dataset.json\n",
      "\n",
      "üìã Next steps for human feedback:\n",
      "\n",
      "1. Start MLflow server:\n",
      "   mlflow server --backend-store-uri sqlite:///mlflow.sqlite --port 5000\n",
      "\n",
      "2. Open MLflow UI at http://127.0.0.1:5000\n",
      "\n",
      "3. Navigate to the experiment 'wiki3-kg-stage1-statements'\n",
      "\n",
      "4. Click on traces to review predictions\n",
      "\n",
      "5. Use the feedback/assessment features to label quality\n",
      "\n",
      "6. Export labeled data for judge improvement\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use human feedback to improve the judge\n",
    "# After collecting labels in MLflow, create DSPy training examples\n",
    "\n",
    "# For now, save the evaluation data for later use\n",
    "output_dir = Path(\"/workspaces/wiki3-kg-project/data/training\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "eval_df.to_json(output_dir / \"eval_dataset.json\", orient=\"records\", indent=2)\n",
    "print(f\"Saved evaluation dataset to {output_dir / 'eval_dataset.json'}\")\n",
    "\n",
    "print(\"\"\"\n",
    "üìã Next steps for human feedback:\n",
    "\n",
    "1. Start MLflow server:\n",
    "   mlflow server --backend-store-uri sqlite:///mlflow.sqlite --port 5000\n",
    "\n",
    "2. Open MLflow UI at http://127.0.0.1:5000\n",
    "\n",
    "3. Navigate to the experiment 'wiki3-kg-stage1-statements'\n",
    "\n",
    "4. Click on traces to review predictions\n",
    "\n",
    "5. Use the feedback/assessment features to label quality\n",
    "\n",
    "6. Export labeled data for judge improvement\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7b175b",
   "metadata": {},
   "source": [
    "## 10. MIPROv2 Prompt Optimization\n",
    "\n",
    "Use DSPy's MIPROv2 optimizer to improve the extractor's prompts.\n",
    "This uses the few-shot examples to bootstrap better demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f711918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import MIPROv2\n",
    "\n",
    "# Configure optimizer\n",
    "optimizer = MIPROv2(\n",
    "    metric=statement_quality_metric,\n",
    "    num_candidates=3,  # Number of prompt candidates to try\n",
    "    init_temperature=0.7,\n",
    ")\n",
    "\n",
    "# Use few-shot examples for bootstrapping demonstrations\n",
    "# Use training set for optimization\n",
    "TRAIN_SIZE = min(20, len(trainset))  # Limit for speed\n",
    "\n",
    "print(f\"Optimizing with {TRAIN_SIZE} training examples...\")\n",
    "print(f\"Using {len(selected_fewshot)} few-shot demos for bootstrapping...\")\n",
    "\n",
    "optimized_extractor = optimizer.compile(\n",
    "    StatementExtractor(),\n",
    "    trainset=trainset[:TRAIN_SIZE],\n",
    "    num_batches=2,\n",
    "    max_bootstrapped_demos=NUM_FEWSHOT,\n",
    "    # Provide few-shot examples as initial demos\n",
    "    # demos=selected_fewshot,  # Uncomment if supported\n",
    ")\n",
    "\n",
    "print(\"\\nOptimization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d59aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate optimized extractor\n",
    "optimized_result = evaluator(optimized_extractor)\n",
    "optimized_score = optimized_result.score if hasattr(optimized_result, 'score') else float(optimized_result)\n",
    "\n",
    "print(f\"Baseline score:  {baseline_score:.2f}\")\n",
    "print(f\"Optimized score: {optimized_score:.2f}\")\n",
    "print(f\"Improvement:     {optimized_score - baseline_score:+.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2fab06",
   "metadata": {},
   "source": [
    "## 11. Inspect Optimized Prompts\n",
    "\n",
    "See what prompts MIPROv2 discovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a08e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the optimized module\n",
    "print(\"Optimized extractor configuration:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Try to access the optimized signature/demos\n",
    "if hasattr(optimized_extractor, 'demos'):\n",
    "    print(f\"\\nDemonstrations: {len(optimized_extractor.demos)}\")\n",
    "    for i, demo in enumerate(optimized_extractor.demos[:2], 1):\n",
    "        print(f\"  Demo {i}: {demo.section_context[:50]}...\")\n",
    "\n",
    "# Check for any instruction changes\n",
    "if hasattr(optimized_extractor, 'signature'):\n",
    "    print(f\"\\nSignature: {optimized_extractor.signature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b0c651",
   "metadata": {},
   "source": [
    "## 12. Save Results\n",
    "\n",
    "Save the optimized extractor and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e45006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training metadata\n",
    "output_dir = Path(\"/workspaces/wiki3-kg-project/data/training\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save training results\n",
    "results = {\n",
    "    \"baseline_score\": baseline_score,\n",
    "    \"optimized_score\": optimized_score,\n",
    "    \"train_size\": TRAIN_SIZE,\n",
    "    \"eval_size\": EVAL_SIZE,\n",
    "    \"num_fewshot\": NUM_FEWSHOT,\n",
    "    \"pages_processed\": pages_processed,\n",
    "    \"total_chunks\": len(training_chunks),\n",
    "}\n",
    "\n",
    "with open(output_dir / \"stage1_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Saved results to {output_dir / 'stage1_results.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized extractor state\n",
    "try:\n",
    "    optimized_extractor.save(output_dir / \"optimized_extractor\")\n",
    "    print(f\"Saved optimized extractor to {output_dir / 'optimized_extractor'}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not save extractor state: {e}\")\n",
    "    # Alternative: save as JSON\n",
    "    if hasattr(optimized_extractor, 'dump_state'):\n",
    "        state = optimized_extractor.dump_state()\n",
    "        with open(output_dir / \"optimized_extractor_state.json\", \"w\") as f:\n",
    "            json.dump(state, f, indent=2)\n",
    "        print(\"Saved extractor state as JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec590ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save few-shot examples for reference\n",
    "fewshot_data = []\n",
    "for ex in selected_fewshot:\n",
    "    fewshot_data.append({\n",
    "        \"chunk_text\": ex.chunk_text,\n",
    "        \"section_context\": ex.section_context,\n",
    "        \"statements\": list(ex.statements),\n",
    "    })\n",
    "\n",
    "with open(output_dir / \"fewshot_examples.json\", \"w\") as f:\n",
    "    json.dump(fewshot_data, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(fewshot_data)} few-shot examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e226c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook:\n",
    "1. Loaded Albert Einstein as few-shot examples (seed/guidance)\n",
    "2. Fetched and chunked Wikipedia sample pages for training\n",
    "3. Established baseline extraction quality\n",
    "4. Ran MIPROv2 prompt optimization\n",
    "5. Saved the optimized extractor\n",
    "\n",
    "Next steps:\n",
    "- **Stage 2**: Schema matching with optimized statements\n",
    "- **Stage 3**: RDF generation training\n",
    "- **Arbor GRPO**: Fine-tune the full pipeline end-to-end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
