{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "sys.path.insert(0, '/workspaces/wiki3-kg-project')\n",
    "\n",
    "import dspy\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from ontological_engineer import (\n",
    "    configure_lm,\n",
    "    StatementExtractor,\n",
    "    StatementQualityJudge,\n",
    ")\n",
    "from ontological_engineer.judges import statement_quality_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0901b9",
   "metadata": {},
   "source": [
    "## 1. Configure Language Model\n",
    "\n",
    "Connect to LM Studio running Qwen-30B (or your preferred model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the LM (defaults to Qwen-30B via LM Studio)\n",
    "lm = configure_lm(\n",
    "    model=\"qwen/qwen3-coder-30b\",\n",
    "    api_base=\"http://host.docker.internal:1234/v1\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(f\"Configured LM: {lm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2783ea44",
   "metadata": {},
   "source": [
    "## 2. Test Statement Extraction\n",
    "\n",
    "Try extracting statements from a sample Wikipedia chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630797b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample chunk from Albert Einstein article\n",
    "sample_chunk = \"\"\"\n",
    "Albert Einstein was born in Ulm, in the Kingdom of WÃ¼rttemberg in the German Empire, \n",
    "on 14 March 1879. His parents, secular Ashkenazi Jews, were Hermann Einstein, \n",
    "a salesman and engineer, and Pauline Koch. In 1880, the family moved to Munich's \n",
    "borough of Ludwigsvorstadt-Isarvorstadt, where Einstein's father and his uncle Jakob \n",
    "founded Elektrotechnische Fabrik J. Einstein & Cie, a company that manufactured \n",
    "electrical equipment based on direct current.\n",
    "\"\"\".strip()\n",
    "\n",
    "sample_context = \"Albert Einstein > Life and career > Childhood, youth and education\"\n",
    "\n",
    "print(\"Chunk text:\")\n",
    "print(sample_chunk)\n",
    "print(f\"\\nContext: {sample_context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0bf5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize extractor and run extraction\n",
    "extractor = StatementExtractor()\n",
    "\n",
    "result = extractor(\n",
    "    chunk_text=sample_chunk,\n",
    "    section_context=sample_context,\n",
    ")\n",
    "\n",
    "print(\"Extracted statements:\")\n",
    "for i, stmt in enumerate(result.statements, 1):\n",
    "    print(f\"  {i}. {stmt}\")\n",
    "\n",
    "if result.reasoning:\n",
    "    print(f\"\\nReasoning: {result.reasoning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebc3ab",
   "metadata": {},
   "source": [
    "## 3. Evaluate Extraction Quality\n",
    "\n",
    "Use the `StatementQualityJudge` to score the extracted statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize judge\n",
    "judge = StatementQualityJudge()\n",
    "\n",
    "# Evaluate the extraction\n",
    "evaluation = judge(\n",
    "    chunk_text=sample_chunk,\n",
    "    section_context=sample_context,\n",
    "    statements=result.statements,\n",
    ")\n",
    "\n",
    "print(\"Quality scores:\")\n",
    "print(f\"  Completeness:      {evaluation.completeness:.2f}\")\n",
    "print(f\"  Atomicity:         {evaluation.atomicity:.2f}\")\n",
    "print(f\"  Accuracy:          {evaluation.accuracy:.2f}\")\n",
    "print(f\"  Link preservation: {evaluation.link_preservation:.2f}\")\n",
    "print(f\"  ---\")\n",
    "print(f\"  Weighted score:    {evaluation.weighted_score:.2f}\")\n",
    "print(f\"\\nReasoning: {evaluation.reasoning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749fd48c",
   "metadata": {},
   "source": [
    "## 4. Load Existing Data for Bootstrapping\n",
    "\n",
    "Load chunks and facts from previous pipeline runs to create training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd64067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ontological_engineer.training.bootstrap import (\n",
    "    load_chunks_from_notebook,\n",
    "    load_facts_from_notebook,\n",
    "    create_training_examples,\n",
    ")\n",
    "\n",
    "# Path to existing data\n",
    "data_dir = Path(\"/workspaces/wiki3-kg-project/data/albert_einstein/20251218_231446\")\n",
    "\n",
    "# Load chunks\n",
    "chunks = load_chunks_from_notebook(data_dir / \"chunks.ipynb\")\n",
    "print(f\"Loaded {len(chunks)} chunks\")\n",
    "\n",
    "# Load facts\n",
    "facts = load_facts_from_notebook(data_dir / \"facts.ipynb\")\n",
    "print(f\"Loaded {len(facts)} fact sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a sample chunk and its extracted facts\n",
    "if chunks and facts:\n",
    "    idx = 0  # Change to explore different chunks\n",
    "    chunk = chunks[idx]\n",
    "    fact_set = facts[idx] if idx < len(facts) else None\n",
    "    \n",
    "    print(f\"Chunk {idx + 1}:\")\n",
    "    print(f\"  Context: {chunk.get('section_context', 'N/A')}\")\n",
    "    print(f\"  Text: {chunk['text'][:200]}...\")\n",
    "    \n",
    "    if fact_set:\n",
    "        print(f\"\\nFacts ({len(fact_set['statements'])} statements):\")\n",
    "        for stmt in fact_set['statements'][:5]:\n",
    "            print(f\"  - {stmt}\")\n",
    "        if len(fact_set['statements']) > 5:\n",
    "            print(f\"  ... and {len(fact_set['statements']) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples from existing data\n",
    "examples = create_training_examples(chunks, facts)\n",
    "print(f\"Created {len(examples)} training examples\")\n",
    "\n",
    "# Show a sample example\n",
    "if examples:\n",
    "    ex = examples[0]\n",
    "    print(f\"\\nSample example:\")\n",
    "    print(f\"  Inputs: chunk_text, section_context\")\n",
    "    print(f\"  Outputs: statements ({len(ex.statements)} items)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b16d6e",
   "metadata": {},
   "source": [
    "## 5. Run DSPy Evaluation\n",
    "\n",
    "Evaluate the extractor on the bootstrapped dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/dev sets\n",
    "from random import shuffle\n",
    "\n",
    "shuffle(examples)\n",
    "split_idx = int(len(examples) * 0.8)\n",
    "trainset = examples[:split_idx]\n",
    "devset = examples[split_idx:]\n",
    "\n",
    "print(f\"Train set: {len(trainset)} examples\")\n",
    "print(f\"Dev set: {len(devset)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on dev set\n",
    "evaluator = dspy.Evaluate(\n",
    "    devset=devset[:5],  # Start with small subset\n",
    "    metric=statement_quality_metric,\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    ")\n",
    "\n",
    "extractor = StatementExtractor()\n",
    "score = evaluator(extractor)\n",
    "\n",
    "print(f\"\\nAverage quality score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2c50a",
   "metadata": {},
   "source": [
    "## 6. MIPROv2 Prompt Optimization (Optional)\n",
    "\n",
    "Run DSPy's prompt optimizer to improve instructions without model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this cell if you want to go straight to GRPO training\n",
    "from dspy.teleprompt import MIPROv2\n",
    "\n",
    "optimizer = MIPROv2(\n",
    "    metric=statement_quality_metric,\n",
    "    num_candidates=3,\n",
    "    init_temperature=0.7,\n",
    ")\n",
    "\n",
    "# This may take a while\n",
    "optimized_extractor = optimizer.compile(\n",
    "    StatementExtractor(),\n",
    "    trainset=trainset[:10],\n",
    "    num_batches=2,\n",
    "    max_bootstrapped_demos=2,\n",
    ")\n",
    "\n",
    "print(\"Optimization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate optimized extractor\n",
    "if 'optimized_extractor' in dir():\n",
    "    optimized_score = evaluator(optimized_extractor)\n",
    "    print(f\"Original score: {score:.2f}\")\n",
    "    print(f\"Optimized score: {optimized_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7209d83d",
   "metadata": {},
   "source": [
    "## 7. Save Training Data\n",
    "\n",
    "Save curated examples for later GRPO training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert examples to JSON-serializable format\n",
    "def example_to_dict(ex):\n",
    "    return {\n",
    "        \"chunk_text\": ex.chunk_text,\n",
    "        \"section_context\": ex.section_context,\n",
    "        \"statements\": ex.statements,\n",
    "    }\n",
    "\n",
    "# Save datasets\n",
    "output_dir = Path(\"/workspaces/wiki3-kg-project/data/training\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "with open(output_dir / \"statement_trainset.json\", \"w\") as f:\n",
    "    json.dump([example_to_dict(ex) for ex in trainset], f, indent=2)\n",
    "\n",
    "with open(output_dir / \"statement_devset.json\", \"w\") as f:\n",
    "    json.dump([example_to_dict(ex) for ex in devset], f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(trainset)} training examples\")\n",
    "print(f\"Saved {len(devset)} dev examples\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
