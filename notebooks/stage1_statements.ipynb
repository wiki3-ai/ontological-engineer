{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9b04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "sys.path.insert(0, '/workspaces/wiki3-kg-project')\n",
    "\n",
    "import dspy\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from ontological_engineer import (\n",
    "    configure_lm,\n",
    "    StatementExtractor,\n",
    "    StatementQualityJudge,\n",
    ")\n",
    "from ontological_engineer.judges import statement_quality_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0901b9",
   "metadata": {},
   "source": [
    "## 1. Configure Language Model\n",
    "\n",
    "Connect to LM Studio running Qwen-30B (or your preferred model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ed2cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured LM: <dspy.clients.lm.LM object at 0xffffb841ada0>\n"
     ]
    }
   ],
   "source": [
    "# Configure the LM (defaults to Qwen-30B via LM Studio)\n",
    "lm = configure_lm(\n",
    "    model=\"qwen/qwen3-coder-30b\",\n",
    "    api_base=\"http://host.docker.internal:1234/v1\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(f\"Configured LM: {lm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2783ea44",
   "metadata": {},
   "source": [
    "## 2. Test Statement Extraction\n",
    "\n",
    "Try extracting statements from a sample Wikipedia chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "630797b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk text:\n",
      "Albert Einstein was born in Ulm, in the Kingdom of Württemberg in the German Empire, \n",
      "on 14 March 1879. His parents, secular Ashkenazi Jews, were Hermann Einstein, \n",
      "a salesman and engineer, and Pauline Koch. In 1880, the family moved to Munich's \n",
      "borough of Ludwigsvorstadt-Isarvorstadt, where Einstein's father and his uncle Jakob \n",
      "founded Elektrotechnische Fabrik J. Einstein & Cie, a company that manufactured \n",
      "electrical equipment based on direct current.\n",
      "\n",
      "Context: Albert Einstein > Life and career > Childhood, youth and education\n"
     ]
    }
   ],
   "source": [
    "# Sample chunk from Albert Einstein article\n",
    "sample_chunk = \"\"\"\n",
    "Albert Einstein was born in Ulm, in the Kingdom of Württemberg in the German Empire, \n",
    "on 14 March 1879. His parents, secular Ashkenazi Jews, were Hermann Einstein, \n",
    "a salesman and engineer, and Pauline Koch. In 1880, the family moved to Munich's \n",
    "borough of Ludwigsvorstadt-Isarvorstadt, where Einstein's father and his uncle Jakob \n",
    "founded Elektrotechnische Fabrik J. Einstein & Cie, a company that manufactured \n",
    "electrical equipment based on direct current.\n",
    "\"\"\".strip()\n",
    "\n",
    "sample_context = \"Albert Einstein > Life and career > Childhood, youth and education\"\n",
    "\n",
    "print(\"Chunk text:\")\n",
    "print(sample_chunk)\n",
    "print(f\"\\nContext: {sample_context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b0bf5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted statements:\n",
      "  1. [Albert Einstein](/wiki/Albert_Einstein) was born in [Ulm](/wiki/Ulm).\n",
      "  2. [Albert Einstein](/wiki/Albert_Einstein) was born on 14 March 1879.\n",
      "  3. [Ulm](/wiki/Ulm) was in the [Kingdom of Württemberg](/wiki/Kingdom_of_Württemberg).\n",
      "  4. [Kingdom of Württemberg](/wiki/Kingdom_of_Württemberg) was in the [German Empire](/wiki/German_Empire).\n",
      "  5. [Albert Einstein](/wiki/Albert_Einstein)'s parents were secular [Ashkenazi Jews](/wiki/Ashkenazi_Jews).\n",
      "  6. [Albert Einstein](/wiki/Albert_Einstein)'s father was [Hermann Einstein](/wiki/Hermann_Einstein).\n",
      "  7. [Hermann Einstein](/wiki/Hermann_Einstein) was a salesman and engineer.\n",
      "  8. [Albert Einstein](/wiki/Albert_Einstein)'s mother was [Pauline Koch](/wiki/Pauline_Koch).\n",
      "  9. In 1880, [Albert Einstein](/wiki/Albert_Einstein)'s family moved to [Munich](/wiki/Munich).\n",
      "  10. [Munich](/wiki/Munich) was in the borough of [Ludwigsvorstadt-Isarvorstadt](/wiki/Ludwigsvorstadt-Isarvorstadt).\n",
      "  11. [Albert Einstein](/wiki/Albert_Einstein)'s father and his uncle [Jakob](/wiki/Jakob_Einstein) founded [Elektrotechnische Fabrik J. Einstein & Cie](/wiki/Elektrotechnische_Fabrik_J._Einstein_%26_Cie).\n",
      "  12. [Elektrotechnische Fabrik J. Einstein & Cie](/wiki/Elektrotechnische_Fabrik_J._Einstein_%26_Cie) manufactured electrical equipment based on direct current.\n",
      "\n",
      "Reasoning: The chunk text describes Albert Einstein's birthplace, family background, and early life circumstances. I need to extract atomic statements that each contain one verifiable claim while preserving the markdown links. The key information includes:\n",
      "1. Einstein's birth details (place and date)\n",
      "2. His parents' backgrounds (secular Ashkenazi Jews)\n",
      "3. His father's name and profession\n",
      "4. His mother's name\n",
      "5. The family's relocation to Munich\n",
      "6. His father and uncle's business venture\n",
      "\n",
      "Each of these constitutes a separate, verifiable claim that can stand alone as an atomic statement.\n"
     ]
    }
   ],
   "source": [
    "# Initialize extractor and run extraction\n",
    "extractor = StatementExtractor()\n",
    "\n",
    "result = extractor(\n",
    "    chunk_text=sample_chunk,\n",
    "    section_context=sample_context,\n",
    ")\n",
    "\n",
    "print(\"Extracted statements:\")\n",
    "for i, stmt in enumerate(result.statements, 1):\n",
    "    print(f\"  {i}. {stmt}\")\n",
    "\n",
    "if result.reasoning:\n",
    "    print(f\"\\nReasoning: {result.reasoning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebc3ab",
   "metadata": {},
   "source": [
    "## 3. Evaluate Extraction Quality\n",
    "\n",
    "Use the `StatementQualityJudge` to score the extracted statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a6000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality scores:\n",
      "  Completeness:      0.90\n",
      "  Atomicity:         1.00\n",
      "  Accuracy:          1.00\n",
      "  Link preservation: 1.00\n",
      "  ---\n",
      "  Weighted score:    0.97\n",
      "\n",
      "Reasoning: The statements accurately reflect the key facts from the chunk text, capturing Einstein's birthplace, date, parents' backgrounds, family relocation, and the founding of the electrical company. Each statement is atomic, focusing on a single verifiable claim without combining multiple ideas. All [Entity](/wiki/...) links are preserved correctly, maintaining the original Wikipedia formatting and references. However, some contextual details like the specific borough name \"Ludwigsvorstadt-Isarvorstadt\" and the company's full name are included, which slightly increases complexity but remains accurate.\n"
     ]
    }
   ],
   "source": [
    "# Initialize judge\n",
    "judge = StatementQualityJudge()\n",
    "\n",
    "# Evaluate the extraction\n",
    "evaluation = judge(\n",
    "    chunk_text=sample_chunk,\n",
    "    section_context=sample_context,\n",
    "    statements=result.statements,\n",
    ")\n",
    "\n",
    "print(\"Quality scores:\")\n",
    "print(f\"  Completeness:      {evaluation.completeness:.2f}\")\n",
    "print(f\"  Atomicity:         {evaluation.atomicity:.2f}\")\n",
    "print(f\"  Accuracy:          {evaluation.accuracy:.2f}\")\n",
    "print(f\"  Link preservation: {evaluation.link_preservation:.2f}\")\n",
    "print(f\"  ---\")\n",
    "print(f\"  Weighted score:    {evaluation.weighted_score:.2f}\")\n",
    "print(f\"\\nReasoning: {evaluation.reasoning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749fd48c",
   "metadata": {},
   "source": [
    "## 4. Load Existing Data for Bootstrapping\n",
    "\n",
    "Load chunks and facts from previous pipeline runs to create training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dd64067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 63 chunks\n",
      "Loaded 19 fact sets\n"
     ]
    }
   ],
   "source": [
    "from ontological_engineer.training.bootstrap import (\n",
    "    load_chunks_from_notebook,\n",
    "    load_facts_from_notebook,\n",
    "    create_training_examples,\n",
    ")\n",
    "\n",
    "# Path to existing data\n",
    "data_dir = Path(\"/workspaces/wiki3-kg-project/data/albert_einstein/20251218_231446\")\n",
    "\n",
    "# Load chunks\n",
    "chunks = load_chunks_from_notebook(data_dir / \"chunks.ipynb\")\n",
    "print(f\"Loaded {len(chunks)} chunks\")\n",
    "\n",
    "# Load facts\n",
    "facts = load_facts_from_notebook(data_dir / \"facts.ipynb\")\n",
    "print(f\"Loaded {len(facts)} fact sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df28f879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "  Context: Albert Einstein > Introduction\n",
      "  Text: Albert Einstein (14 March 1879 – 18 April 1955) was a German-born theoretical physicist best known for developing the theory of relativity. Einstein also made important contributions to quantum theory...\n",
      "\n",
      "Facts (28 statements):\n",
      "  - Albert Einstein was a German-born theoretical physicist.\n",
      "  - Albert Einstein developed the theory of relativity.\n",
      "  - Albert Einstein made important contributions to quantum theory.\n",
      "  - Albert Einstein's mass–energy equivalence formula E = mc2 arises from special relativity.\n",
      "  - Albert Einstein received the 1921 Nobel Prize in Physics.\n",
      "  ... and 23 more\n"
     ]
    }
   ],
   "source": [
    "# Show a sample chunk and its extracted facts\n",
    "if chunks and facts:\n",
    "    idx = 0  # Change to explore different chunks\n",
    "    chunk = chunks[idx]\n",
    "    fact_set = facts[idx] if idx < len(facts) else None\n",
    "    \n",
    "    print(f\"Chunk {idx + 1}:\")\n",
    "    print(f\"  Context: {chunk.get('section_context', 'N/A')}\")\n",
    "    print(f\"  Text: {chunk['text'][:200]}...\")\n",
    "    \n",
    "    if fact_set:\n",
    "        print(f\"\\nFacts ({len(fact_set['statements'])} statements):\")\n",
    "        for stmt in fact_set['statements'][:5]:\n",
    "            print(f\"  - {stmt}\")\n",
    "        if len(fact_set['statements']) > 5:\n",
    "            print(f\"  ... and {len(fact_set['statements']) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "678c669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 19 training examples\n",
      "\n",
      "Sample example:\n",
      "  Inputs: chunk_text, section_context\n",
      "  Outputs: statements (28 items)\n"
     ]
    }
   ],
   "source": [
    "# Create training examples from existing data\n",
    "examples = create_training_examples(chunks, facts)\n",
    "print(f\"Created {len(examples)} training examples\")\n",
    "\n",
    "# Show a sample example\n",
    "if examples:\n",
    "    ex = examples[0]\n",
    "    print(f\"\\nSample example:\")\n",
    "    print(f\"  Inputs: chunk_text, section_context\")\n",
    "    print(f\"  Outputs: statements ({len(ex.statements)} items)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b16d6e",
   "metadata": {},
   "source": [
    "## 5. Run DSPy Evaluation\n",
    "\n",
    "Evaluate the extractor on the bootstrapped dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59af0fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 15 examples\n",
      "Dev set: 4 examples\n"
     ]
    }
   ],
   "source": [
    "# Split into train/dev sets\n",
    "from random import shuffle\n",
    "\n",
    "shuffle(examples)\n",
    "split_idx = int(len(examples) * 0.8)\n",
    "trainset = examples[:split_idx]\n",
    "devset = examples[split_idx:]\n",
    "\n",
    "print(f\"Train set: {len(trainset)} examples\")\n",
    "print(f\"Dev set: {len(devset)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cba4011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.90 / 4 (97.5%): 100%|██████████| 4/4 [00:00<00:00, 259.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/20 00:52:05 INFO dspy.evaluate.evaluate: Average Metric: 3.9 / 4 (97.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average quality score: 97.50\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on dev set\n",
    "evaluator = dspy.Evaluate(\n",
    "    devset=devset[:5],  # Start with small subset\n",
    "    metric=statement_quality_metric,\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    ")\n",
    "\n",
    "extractor = StatementExtractor()\n",
    "result = evaluator(extractor)\n",
    "\n",
    "# EvaluationResult has a score attribute\n",
    "score = result.score if hasattr(result, 'score') else float(result)\n",
    "print(f\"\\nAverage quality score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2c50a",
   "metadata": {},
   "source": [
    "## 6. MIPROv2 Prompt Optimization (Optional)\n",
    "\n",
    "Run DSPy's prompt optimizer to improve instructions without model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this cell if you want to go straight to GRPO training\n",
    "from dspy.teleprompt import MIPROv2\n",
    "\n",
    "optimizer = MIPROv2(\n",
    "    metric=statement_quality_metric,\n",
    "    num_candidates=3,\n",
    "    init_temperature=0.7,\n",
    ")\n",
    "\n",
    "# This may take a while\n",
    "optimized_extractor = optimizer.compile(\n",
    "    StatementExtractor(),\n",
    "    trainset=trainset[:10],\n",
    "    num_batches=2,\n",
    "    max_bootstrapped_demos=2,\n",
    ")\n",
    "\n",
    "print(\"Optimization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate optimized extractor\n",
    "if 'optimized_extractor' in dir():\n",
    "    optimized_score = evaluator(optimized_extractor)\n",
    "    print(f\"Original score: {score:.2f}\")\n",
    "    print(f\"Optimized score: {optimized_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7209d83d",
   "metadata": {},
   "source": [
    "## 7. Save Training Data\n",
    "\n",
    "Save curated examples for later GRPO training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert examples to JSON-serializable format\n",
    "def example_to_dict(ex):\n",
    "    return {\n",
    "        \"chunk_text\": ex.chunk_text,\n",
    "        \"section_context\": ex.section_context,\n",
    "        \"statements\": ex.statements,\n",
    "    }\n",
    "\n",
    "# Save datasets\n",
    "output_dir = Path(\"/workspaces/wiki3-kg-project/data/training\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "with open(output_dir / \"statement_trainset.json\", \"w\") as f:\n",
    "    json.dump([example_to_dict(ex) for ex in trainset], f, indent=2)\n",
    "\n",
    "with open(output_dir / \"statement_devset.json\", \"w\") as f:\n",
    "    json.dump([example_to_dict(ex) for ex in devset], f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(trainset)} training examples\")\n",
    "print(f\"Saved {len(devset)} dev examples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
