Have the statement extractor generate a list of triples in english for each sentence,
then run similarity search against the schema for reasonable matches to add as a set (deduped) to the prompt (via a template var) for each statement set.


Gotta have ontology inference to handle cases like these:


<https://en.wikipedia.org/wiki/Albert_Einstein#quote6> a schema:Quotation ;
    schema:text "I observed that without 'ethical culture' there is no salvation for humanity." ;
    schema:spokenByCharacter <https://en.wikipedia.org/wiki/Albert_Einstein#person_albert_einstein> .

The actual quote is "Without 'ethical culture' there is no salvation for humanity."

<https://en.wikipedia.org/wiki/Albert_Einstein#quote3> a schema:Quotation ;
    schema:text "I described my view of God as naïve and preferred to call myself an agnostic or a 'deeply religious nonbeliever'." ;
    schema:spokenByCharacter <https://en.wikipedia.org/wiki/Albert_Einstein#person_albert_einstein> .


# Statement [1.30]: [Albert Einstein](/wiki/Albert_Einstein) was a physicist.
<https://en.wikipedia.org/wiki/Albert_Einstein> rdf:type schema:Person .


The actual quotes are "I am not an atheist" and "deeply religious nonbeliever" from:

He did not believe in a personal god who concerns himself with fates and actions of human beings, a view which he described as naïve.[190]  He clarified, however, that "I am not an atheist",[191] preferring to call himself an agnostic,[192][193] or a "deeply religious nonbeliever".

We should be able to get the verification property that quotations are verbatim copies of suitably sourced material given the context (i.e. microtheory).   Here we're making claims/an analysis/inference based on what Wikipedia says.  Wikipedia intends that they follow a similar consensus editorial policy so it (usually) provides sources for all statements of "fact".  Next level for our output is to then go (attempt to) retrieve those sources and mine them for their quality, corrections, etc.

Real time Snopes (snoping?) captions for live (and of course redistributed) broadcasts.
And of course wiki3.ai is there is help anyone who has a different PoV to make their claims.



Need to use an RL framework for prompting and the schema tool.
DSPy, prime-RL, verifiers?
The reproducible compute graph and LLM and human / agent feedback for wiki3.ai.

2025/12/20 08:12:34 ERROR dspy.utils.parallelizer: Error for Example({'chunk_text': '. The Republican-leaning areas will then be split among the strongly Democratic San Diego-based districts.\nThe new map will also decrease the competitiveness of several swing districts held by Democrats:', 'section_context': '2025 California Proposition 50 > Passed map'}) (input_keys={'chunk_text', 'section_context'}): litellm.BadRequestError: OpenAIException - Error code: 400 - {'error': "'response_format.type' must be 'json_schema' or 'text'"}. Set `provide_traceback=True` for traceback.


Statement Judge needs to also score whether information came from the chunk and whether all the relevant information in the chunk has statements in the output.

Provenance and dependency needs to have text that changes in notebooks.  
For functional code not in notebooks we need a way to determine equivalance.
That's what the formalization is for; statements about behavior.
Code is equivalent if the theorems/tests that are stated as passing or not passing for it are the same.
When bugs/unattested behavior is discovered for existing code we make statements about them.
